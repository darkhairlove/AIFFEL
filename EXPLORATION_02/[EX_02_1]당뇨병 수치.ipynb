{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d8f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ae27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "783208a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d83a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7aa7a",
   "metadata": {},
   "source": [
    "# 1. 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe08e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = diabetes.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dee704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03807591  0.05068012  0.06169621 ... -0.00259226  0.01990842\n",
      "  -0.01764613]\n",
      " [-0.00188202 -0.04464164 -0.05147406 ... -0.03949338 -0.06832974\n",
      "  -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 ... -0.00259226  0.00286377\n",
      "  -0.02593034]\n",
      " ...\n",
      " [ 0.04170844  0.05068012 -0.01590626 ... -0.01107952 -0.04687948\n",
      "   0.01549073]\n",
      " [-0.04547248 -0.04464164  0.03906215 ...  0.02655962  0.04452837\n",
      "  -0.02593034]\n",
      " [-0.04547248 -0.04464164 -0.0730303  ... -0.03949338 -0.00421986\n",
      "   0.00306441]]\n",
      "(442, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_X)\n",
    "print(df_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6dd0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70de06c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151.  75. 141. 206. 135.  97. 138.  63. 110. 310. 101.  69. 179. 185.\n",
      " 118. 171. 166. 144.  97. 168.  68.  49.  68. 245. 184. 202. 137.  85.\n",
      " 131. 283. 129.  59. 341.  87.  65. 102. 265. 276. 252.  90. 100.  55.\n",
      "  61.  92. 259.  53. 190. 142.  75. 142. 155. 225.  59. 104. 182. 128.\n",
      "  52.  37. 170. 170.  61. 144.  52. 128.  71. 163. 150.  97. 160. 178.\n",
      "  48. 270. 202. 111.  85.  42. 170. 200. 252. 113. 143.  51.  52. 210.\n",
      "  65. 141.  55. 134.  42. 111.  98. 164.  48.  96.  90. 162. 150. 279.\n",
      "  92.  83. 128. 102. 302. 198.  95.  53. 134. 144. 232.  81. 104.  59.\n",
      " 246. 297. 258. 229. 275. 281. 179. 200. 200. 173. 180.  84. 121. 161.\n",
      "  99. 109. 115. 268. 274. 158. 107.  83. 103. 272.  85. 280. 336. 281.\n",
      " 118. 317. 235.  60. 174. 259. 178. 128.  96. 126. 288.  88. 292.  71.\n",
      " 197. 186.  25.  84.  96. 195.  53. 217. 172. 131. 214.  59.  70. 220.\n",
      " 268. 152.  47.  74. 295. 101. 151. 127. 237. 225.  81. 151. 107.  64.\n",
      " 138. 185. 265. 101. 137. 143. 141.  79. 292. 178.  91. 116.  86. 122.\n",
      "  72. 129. 142.  90. 158.  39. 196. 222. 277.  99. 196. 202. 155.  77.\n",
      " 191.  70.  73.  49.  65. 263. 248. 296. 214. 185.  78.  93. 252. 150.\n",
      "  77. 208.  77. 108. 160.  53. 220. 154. 259.  90. 246. 124.  67.  72.\n",
      " 257. 262. 275. 177.  71.  47. 187. 125.  78.  51. 258. 215. 303. 243.\n",
      "  91. 150. 310. 153. 346.  63.  89.  50.  39. 103. 308. 116. 145.  74.\n",
      "  45. 115. 264.  87. 202. 127. 182. 241.  66.  94. 283.  64. 102. 200.\n",
      " 265.  94. 230. 181. 156. 233.  60. 219.  80.  68. 332. 248.  84. 200.\n",
      "  55.  85.  89.  31. 129.  83. 275.  65. 198. 236. 253. 124.  44. 172.\n",
      " 114. 142. 109. 180. 144. 163. 147.  97. 220. 190. 109. 191. 122. 230.\n",
      " 242. 248. 249. 192. 131. 237.  78. 135. 244. 199. 270. 164.  72.  96.\n",
      " 306.  91. 214.  95. 216. 263. 178. 113. 200. 139. 139.  88. 148.  88.\n",
      " 243.  71.  77. 109. 272.  60.  54. 221.  90. 311. 281. 182. 321.  58.\n",
      " 262. 206. 233. 242. 123. 167.  63. 197.  71. 168. 140. 217. 121. 235.\n",
      " 245.  40.  52. 104. 132.  88.  69. 219.  72. 201. 110.  51. 277.  63.\n",
      " 118.  69. 273. 258.  43. 198. 242. 232. 175.  93. 168. 275. 293. 281.\n",
      "  72. 140. 189. 181. 209. 136. 261. 113. 131. 174. 257.  55.  84.  42.\n",
      " 146. 212. 233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.\n",
      "  49.  64.  48. 178. 104. 132. 220.  57.]\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(df_y)\n",
    "print(df_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22c269",
   "metadata": {},
   "source": [
    "# 2. 모델에 입력할 데이터 X 준비, 예측할 데이터 y 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68ff7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e118fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_X)\n",
    "y = np.array(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c07a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3f740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151.  75. 141. 206. 135.  97. 138.  63. 110. 310. 101.  69. 179. 185.\n",
      " 118. 171. 166. 144.  97. 168.  68.  49.  68. 245. 184. 202. 137.  85.\n",
      " 131. 283. 129.  59. 341.  87.  65. 102. 265. 276. 252.  90. 100.  55.\n",
      "  61.  92. 259.  53. 190. 142.  75. 142. 155. 225.  59. 104. 182. 128.\n",
      "  52.  37. 170. 170.  61. 144.  52. 128.  71. 163. 150.  97. 160. 178.\n",
      "  48. 270. 202. 111.  85.  42. 170. 200. 252. 113. 143.  51.  52. 210.\n",
      "  65. 141.  55. 134.  42. 111.  98. 164.  48.  96.  90. 162. 150. 279.\n",
      "  92.  83. 128. 102. 302. 198.  95.  53. 134. 144. 232.  81. 104.  59.\n",
      " 246. 297. 258. 229. 275. 281. 179. 200. 200. 173. 180.  84. 121. 161.\n",
      "  99. 109. 115. 268. 274. 158. 107.  83. 103. 272.  85. 280. 336. 281.\n",
      " 118. 317. 235.  60. 174. 259. 178. 128.  96. 126. 288.  88. 292.  71.\n",
      " 197. 186.  25.  84.  96. 195.  53. 217. 172. 131. 214.  59.  70. 220.\n",
      " 268. 152.  47.  74. 295. 101. 151. 127. 237. 225.  81. 151. 107.  64.\n",
      " 138. 185. 265. 101. 137. 143. 141.  79. 292. 178.  91. 116.  86. 122.\n",
      "  72. 129. 142.  90. 158.  39. 196. 222. 277.  99. 196. 202. 155.  77.\n",
      " 191.  70.  73.  49.  65. 263. 248. 296. 214. 185.  78.  93. 252. 150.\n",
      "  77. 208.  77. 108. 160.  53. 220. 154. 259.  90. 246. 124.  67.  72.\n",
      " 257. 262. 275. 177.  71.  47. 187. 125.  78.  51. 258. 215. 303. 243.\n",
      "  91. 150. 310. 153. 346.  63.  89.  50.  39. 103. 308. 116. 145.  74.\n",
      "  45. 115. 264.  87. 202. 127. 182. 241.  66.  94. 283.  64. 102. 200.\n",
      " 265.  94. 230. 181. 156. 233.  60. 219.  80.  68. 332. 248.  84. 200.\n",
      "  55.  85.  89.  31. 129.  83. 275.  65. 198. 236. 253. 124.  44. 172.\n",
      " 114. 142. 109. 180. 144. 163. 147.  97. 220. 190. 109. 191. 122. 230.\n",
      " 242. 248. 249. 192. 131. 237.  78. 135. 244. 199. 270. 164.  72.  96.\n",
      " 306.  91. 214.  95. 216. 263. 178. 113. 200. 139. 139.  88. 148.  88.\n",
      " 243.  71.  77. 109. 272.  60.  54. 221.  90. 311. 281. 182. 321.  58.\n",
      " 262. 206. 233. 242. 123. 167.  63. 197.  71. 168. 140. 217. 121. 235.\n",
      " 245.  40.  52. 104. 132.  88.  69. 219.  72. 201. 110.  51. 277.  63.\n",
      " 118.  69. 273. 258.  43. 198. 242. 232. 175.  93. 168. 275. 293. 281.\n",
      "  72. 140. 189. 181. 209. 136. 261. 113. 131. 174. 257.  55.  84.  42.\n",
      " 146. 212. 233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.\n",
      "  49.  64.  48. 178. 104. 132. 220.  57.]\n"
     ]
    }
   ],
   "source": [
    "type(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc7e88",
   "metadata": {},
   "source": [
    "# 3. 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71705edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034f716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :  (353, 10) y_train shape  :  (353,)\n",
      "X_test shape  :  (89, 10) y_test shape  :  (89,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(\"X_train shape : \", X_train.shape,\"y_train shape  : \", y_train.shape)\n",
    "\n",
    "print(\"X_test shape  : \", X_test.shape,\"y_test shape  : \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6939474",
   "metadata": {},
   "source": [
    "# 4.모델 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "276a5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 W, b\n",
    "W = np.random.rand(10)\n",
    "b = np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "907c3b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42638976, 0.24633326, 0.36916348, 0.58232195, 0.74374626,\n",
       "       0.41374266, 0.27628885, 0.77052392, 0.42530773, 0.80967429])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f6b2175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7416984434673345"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa22af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 함수\n",
    "def model(X, W, b):\n",
    "    predictions = 0\n",
    "    for i in range(10):\n",
    "        predictions += X[:, i] * W[i]\n",
    "    predictions += b\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc83aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE 함수\n",
    "def MSE(a, b):\n",
    "    mse = ((a-b)**2).mean() # 두 값의 차이의 제곱의 평균\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba1e8b",
   "metadata": {},
   "source": [
    "# 5.loss 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4abd44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 함수를 MSE 함수로 정의\n",
    "def loss(X, W, b, y):\n",
    "    predictions = model(X, W, b)\n",
    "    L = MSE(predictions, y)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf39b2f",
   "metadata": {},
   "source": [
    "# 6. gradient 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65e95857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, W, b, y):\n",
    "    N = len(W)\n",
    "    y_pred = model(X, W, b)\n",
    "    dW = 1/N * 2 * X.T.dot(y_pred - y)\n",
    "    db = 2 * (y_pred - y).mean()\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7029e2a",
   "metadata": {},
   "source": [
    "# 7. 학습률 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c122fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c897c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 : Loss 28518.5905\n",
      "Iteration 20 : Loss 27602.6144\n",
      "Iteration 30 : Loss 26721.8862\n",
      "Iteration 40 : Loss 25875.0293\n",
      "Iteration 50 : Loss 25060.7211\n",
      "Iteration 60 : Loss 24277.6909\n",
      "Iteration 70 : Loss 23524.7178\n",
      "Iteration 80 : Loss 22800.6288\n",
      "Iteration 90 : Loss 22104.2969\n",
      "Iteration 100 : Loss 21434.6390\n",
      "Iteration 110 : Loss 20790.6148\n",
      "Iteration 120 : Loss 20171.2246\n",
      "Iteration 130 : Loss 19575.5078\n",
      "Iteration 140 : Loss 19002.5418\n",
      "Iteration 150 : Loss 18451.4396\n",
      "Iteration 160 : Loss 17921.3495\n",
      "Iteration 170 : Loss 17411.4528\n",
      "Iteration 180 : Loss 16920.9629\n",
      "Iteration 190 : Loss 16449.1243\n",
      "Iteration 200 : Loss 15995.2108\n",
      "Iteration 210 : Loss 15558.5247\n",
      "Iteration 220 : Loss 15138.3957\n",
      "Iteration 230 : Loss 14734.1798\n",
      "Iteration 240 : Loss 14345.2580\n",
      "Iteration 250 : Loss 13971.0358\n",
      "Iteration 260 : Loss 13610.9417\n",
      "Iteration 270 : Loss 13264.4269\n",
      "Iteration 280 : Loss 12930.9638\n",
      "Iteration 290 : Loss 12610.0456\n",
      "Iteration 300 : Loss 12301.1852\n",
      "Iteration 310 : Loss 12003.9148\n",
      "Iteration 320 : Loss 11717.7847\n",
      "Iteration 330 : Loss 11442.3628\n",
      "Iteration 340 : Loss 11177.2340\n",
      "Iteration 350 : Loss 10921.9995\n",
      "Iteration 360 : Loss 10676.2758\n",
      "Iteration 370 : Loss 10439.6948\n",
      "Iteration 380 : Loss 10211.9025\n",
      "Iteration 390 : Loss 9992.5588\n",
      "Iteration 400 : Loss 9781.3370\n",
      "Iteration 410 : Loss 9577.9230\n",
      "Iteration 420 : Loss 9382.0153\n",
      "Iteration 430 : Loss 9193.3237\n",
      "Iteration 440 : Loss 9011.5697\n",
      "Iteration 450 : Loss 8836.4857\n",
      "Iteration 460 : Loss 8667.8143\n",
      "Iteration 470 : Loss 8505.3083\n",
      "Iteration 480 : Loss 8348.7302\n",
      "Iteration 490 : Loss 8197.8517\n",
      "Iteration 500 : Loss 8052.4534\n",
      "Iteration 510 : Loss 7912.3246\n",
      "Iteration 520 : Loss 7777.2626\n",
      "Iteration 530 : Loss 7647.0728\n",
      "Iteration 540 : Loss 7521.5681\n",
      "Iteration 550 : Loss 7400.5687\n",
      "Iteration 560 : Loss 7283.9018\n",
      "Iteration 570 : Loss 7171.4015\n",
      "Iteration 580 : Loss 7062.9081\n",
      "Iteration 590 : Loss 6958.2683\n",
      "Iteration 600 : Loss 6857.3348\n",
      "Iteration 610 : Loss 6759.9660\n",
      "Iteration 620 : Loss 6666.0256\n",
      "Iteration 630 : Loss 6575.3830\n",
      "Iteration 640 : Loss 6487.9123\n",
      "Iteration 650 : Loss 6403.4929\n",
      "Iteration 660 : Loss 6322.0085\n",
      "Iteration 670 : Loss 6243.3475\n",
      "Iteration 680 : Loss 6167.4028\n",
      "Iteration 690 : Loss 6094.0711\n",
      "Iteration 700 : Loss 6023.2535\n",
      "Iteration 710 : Loss 5954.8547\n",
      "Iteration 720 : Loss 5888.7831\n",
      "Iteration 730 : Loss 5824.9508\n",
      "Iteration 740 : Loss 5763.2732\n",
      "Iteration 750 : Loss 5703.6691\n",
      "Iteration 760 : Loss 5646.0603\n",
      "Iteration 770 : Loss 5590.3717\n",
      "Iteration 780 : Loss 5536.5311\n",
      "Iteration 790 : Loss 5484.4692\n",
      "Iteration 800 : Loss 5434.1192\n",
      "Iteration 810 : Loss 5385.4170\n",
      "Iteration 820 : Loss 5338.3011\n",
      "Iteration 830 : Loss 5292.7121\n",
      "Iteration 840 : Loss 5248.5931\n",
      "Iteration 850 : Loss 5205.8894\n",
      "Iteration 860 : Loss 5164.5483\n",
      "Iteration 870 : Loss 5124.5192\n",
      "Iteration 880 : Loss 5085.7535\n",
      "Iteration 890 : Loss 5048.2043\n",
      "Iteration 900 : Loss 5011.8268\n",
      "Iteration 910 : Loss 4976.5778\n",
      "Iteration 920 : Loss 4942.4155\n",
      "Iteration 930 : Loss 4909.3001\n",
      "Iteration 940 : Loss 4877.1932\n",
      "Iteration 950 : Loss 4846.0578\n",
      "Iteration 960 : Loss 4815.8583\n",
      "Iteration 970 : Loss 4786.5607\n",
      "Iteration 980 : Loss 4758.1320\n",
      "Iteration 990 : Loss 4730.5408\n",
      "Iteration 1000 : Loss 4703.7565\n",
      "Iteration 1010 : Loss 4677.7501\n",
      "Iteration 1020 : Loss 4652.4934\n",
      "Iteration 1030 : Loss 4627.9594\n",
      "Iteration 1040 : Loss 4604.1221\n",
      "Iteration 1050 : Loss 4580.9565\n",
      "Iteration 1060 : Loss 4558.4387\n",
      "Iteration 1070 : Loss 4536.5454\n",
      "Iteration 1080 : Loss 4515.2545\n",
      "Iteration 1090 : Loss 4494.5446\n",
      "Iteration 1100 : Loss 4474.3951\n",
      "Iteration 1110 : Loss 4454.7862\n",
      "Iteration 1120 : Loss 4435.6988\n",
      "Iteration 1130 : Loss 4417.1148\n",
      "Iteration 1140 : Loss 4399.0164\n",
      "Iteration 1150 : Loss 4381.3867\n",
      "Iteration 1160 : Loss 4364.2094\n",
      "Iteration 1170 : Loss 4347.4688\n",
      "Iteration 1180 : Loss 4331.1498\n",
      "Iteration 1190 : Loss 4315.2380\n",
      "Iteration 1200 : Loss 4299.7192\n",
      "Iteration 1210 : Loss 4284.5801\n",
      "Iteration 1220 : Loss 4269.8078\n",
      "Iteration 1230 : Loss 4255.3896\n",
      "Iteration 1240 : Loss 4241.3138\n",
      "Iteration 1250 : Loss 4227.5687\n",
      "Iteration 1260 : Loss 4214.1432\n",
      "Iteration 1270 : Loss 4201.0267\n",
      "Iteration 1280 : Loss 4188.2088\n",
      "Iteration 1290 : Loss 4175.6797\n",
      "Iteration 1300 : Loss 4163.4297\n",
      "Iteration 1310 : Loss 4151.4498\n",
      "Iteration 1320 : Loss 4139.7310\n",
      "Iteration 1330 : Loss 4128.2649\n",
      "Iteration 1340 : Loss 4117.0433\n",
      "Iteration 1350 : Loss 4106.0582\n",
      "Iteration 1360 : Loss 4095.3022\n",
      "Iteration 1370 : Loss 4084.7677\n",
      "Iteration 1380 : Loss 4074.4479\n",
      "Iteration 1390 : Loss 4064.3358\n",
      "Iteration 1400 : Loss 4054.4250\n",
      "Iteration 1410 : Loss 4044.7092\n",
      "Iteration 1420 : Loss 4035.1822\n",
      "Iteration 1430 : Loss 4025.8383\n",
      "Iteration 1440 : Loss 4016.6717\n",
      "Iteration 1450 : Loss 4007.6771\n",
      "Iteration 1460 : Loss 3998.8492\n",
      "Iteration 1470 : Loss 3990.1830\n",
      "Iteration 1480 : Loss 3981.6735\n",
      "Iteration 1490 : Loss 3973.3162\n",
      "Iteration 1500 : Loss 3965.1065\n",
      "Iteration 1510 : Loss 3957.0400\n",
      "Iteration 1520 : Loss 3949.1125\n",
      "Iteration 1530 : Loss 3941.3200\n",
      "Iteration 1540 : Loss 3933.6586\n",
      "Iteration 1550 : Loss 3926.1244\n",
      "Iteration 1560 : Loss 3918.7139\n",
      "Iteration 1570 : Loss 3911.4236\n",
      "Iteration 1580 : Loss 3904.2501\n",
      "Iteration 1590 : Loss 3897.1900\n",
      "Iteration 1600 : Loss 3890.2403\n",
      "Iteration 1610 : Loss 3883.3979\n",
      "Iteration 1620 : Loss 3876.6599\n",
      "Iteration 1630 : Loss 3870.0234\n",
      "Iteration 1640 : Loss 3863.4858\n",
      "Iteration 1650 : Loss 3857.0443\n",
      "Iteration 1660 : Loss 3850.6964\n",
      "Iteration 1670 : Loss 3844.4397\n",
      "Iteration 1680 : Loss 3838.2718\n",
      "Iteration 1690 : Loss 3832.1903\n",
      "Iteration 1700 : Loss 3826.1932\n",
      "Iteration 1710 : Loss 3820.2781\n",
      "Iteration 1720 : Loss 3814.4431\n",
      "Iteration 1730 : Loss 3808.6862\n",
      "Iteration 1740 : Loss 3803.0053\n",
      "Iteration 1750 : Loss 3797.3987\n",
      "Iteration 1760 : Loss 3791.8646\n",
      "Iteration 1770 : Loss 3786.4011\n",
      "Iteration 1780 : Loss 3781.0067\n",
      "Iteration 1790 : Loss 3775.6796\n",
      "Iteration 1800 : Loss 3770.4182\n",
      "Iteration 1810 : Loss 3765.2212\n",
      "Iteration 1820 : Loss 3760.0868\n",
      "Iteration 1830 : Loss 3755.0139\n",
      "Iteration 1840 : Loss 3750.0008\n",
      "Iteration 1850 : Loss 3745.0464\n",
      "Iteration 1860 : Loss 3740.1493\n",
      "Iteration 1870 : Loss 3735.3082\n",
      "Iteration 1880 : Loss 3730.5219\n",
      "Iteration 1890 : Loss 3725.7893\n",
      "Iteration 1900 : Loss 3721.1092\n",
      "Iteration 1910 : Loss 3716.4804\n",
      "Iteration 1920 : Loss 3711.9020\n",
      "Iteration 1930 : Loss 3707.3728\n",
      "Iteration 1940 : Loss 3702.8919\n",
      "Iteration 1950 : Loss 3698.4582\n",
      "Iteration 1960 : Loss 3694.0709\n",
      "Iteration 1970 : Loss 3689.7290\n",
      "Iteration 1980 : Loss 3685.4316\n",
      "Iteration 1990 : Loss 3681.1778\n",
      "Iteration 2000 : Loss 3676.9668\n",
      "Iteration 2010 : Loss 3672.7978\n",
      "Iteration 2020 : Loss 3668.6700\n",
      "Iteration 2030 : Loss 3664.5825\n",
      "Iteration 2040 : Loss 3660.5348\n",
      "Iteration 2050 : Loss 3656.5259\n",
      "Iteration 2060 : Loss 3652.5553\n",
      "Iteration 2070 : Loss 3648.6222\n",
      "Iteration 2080 : Loss 3644.7260\n",
      "Iteration 2090 : Loss 3640.8660\n",
      "Iteration 2100 : Loss 3637.0416\n",
      "Iteration 2110 : Loss 3633.2522\n",
      "Iteration 2120 : Loss 3629.4971\n",
      "Iteration 2130 : Loss 3625.7758\n",
      "Iteration 2140 : Loss 3622.0877\n",
      "Iteration 2150 : Loss 3618.4323\n",
      "Iteration 2160 : Loss 3614.8091\n",
      "Iteration 2170 : Loss 3611.2174\n",
      "Iteration 2180 : Loss 3607.6569\n",
      "Iteration 2190 : Loss 3604.1269\n",
      "Iteration 2200 : Loss 3600.6271\n",
      "Iteration 2210 : Loss 3597.1569\n",
      "Iteration 2220 : Loss 3593.7159\n",
      "Iteration 2230 : Loss 3590.3036\n",
      "Iteration 2240 : Loss 3586.9196\n",
      "Iteration 2250 : Loss 3583.5635\n",
      "Iteration 2260 : Loss 3580.2349\n",
      "Iteration 2270 : Loss 3576.9333\n",
      "Iteration 2280 : Loss 3573.6584\n",
      "Iteration 2290 : Loss 3570.4097\n",
      "Iteration 2300 : Loss 3567.1870\n",
      "Iteration 2310 : Loss 3563.9897\n",
      "Iteration 2320 : Loss 3560.8177\n",
      "Iteration 2330 : Loss 3557.6704\n",
      "Iteration 2340 : Loss 3554.5476\n",
      "Iteration 2350 : Loss 3551.4489\n",
      "Iteration 2360 : Loss 3548.3741\n",
      "Iteration 2370 : Loss 3545.3227\n",
      "Iteration 2380 : Loss 3542.2945\n",
      "Iteration 2390 : Loss 3539.2891\n",
      "Iteration 2400 : Loss 3536.3063\n",
      "Iteration 2410 : Loss 3533.3457\n",
      "Iteration 2420 : Loss 3530.4071\n",
      "Iteration 2430 : Loss 3527.4903\n",
      "Iteration 2440 : Loss 3524.5948\n",
      "Iteration 2450 : Loss 3521.7205\n",
      "Iteration 2460 : Loss 3518.8670\n",
      "Iteration 2470 : Loss 3516.0342\n",
      "Iteration 2480 : Loss 3513.2217\n",
      "Iteration 2490 : Loss 3510.4294\n",
      "Iteration 2500 : Loss 3507.6569\n",
      "Iteration 2510 : Loss 3504.9040\n",
      "Iteration 2520 : Loss 3502.1706\n",
      "Iteration 2530 : Loss 3499.4563\n",
      "Iteration 2540 : Loss 3496.7609\n",
      "Iteration 2550 : Loss 3494.0843\n",
      "Iteration 2560 : Loss 3491.4262\n",
      "Iteration 2570 : Loss 3488.7863\n",
      "Iteration 2580 : Loss 3486.1645\n",
      "Iteration 2590 : Loss 3483.5606\n",
      "Iteration 2600 : Loss 3480.9744\n",
      "Iteration 2610 : Loss 3478.4056\n",
      "Iteration 2620 : Loss 3475.8541\n",
      "Iteration 2630 : Loss 3473.3197\n",
      "Iteration 2640 : Loss 3470.8022\n",
      "Iteration 2650 : Loss 3468.3014\n",
      "Iteration 2660 : Loss 3465.8172\n",
      "Iteration 2670 : Loss 3463.3492\n",
      "Iteration 2680 : Loss 3460.8975\n",
      "Iteration 2690 : Loss 3458.4617\n",
      "Iteration 2700 : Loss 3456.0418\n",
      "Iteration 2710 : Loss 3453.6376\n",
      "Iteration 2720 : Loss 3451.2488\n",
      "Iteration 2730 : Loss 3448.8754\n",
      "Iteration 2740 : Loss 3446.5172\n",
      "Iteration 2750 : Loss 3444.1740\n",
      "Iteration 2760 : Loss 3441.8456\n",
      "Iteration 2770 : Loss 3439.5320\n",
      "Iteration 2780 : Loss 3437.2330\n",
      "Iteration 2790 : Loss 3434.9483\n",
      "Iteration 2800 : Loss 3432.6780\n",
      "Iteration 2810 : Loss 3430.4218\n",
      "Iteration 2820 : Loss 3428.1796\n",
      "Iteration 2830 : Loss 3425.9512\n",
      "Iteration 2840 : Loss 3423.7366\n",
      "Iteration 2850 : Loss 3421.5355\n",
      "Iteration 2860 : Loss 3419.3479\n",
      "Iteration 2870 : Loss 3417.1737\n",
      "Iteration 2880 : Loss 3415.0126\n",
      "Iteration 2890 : Loss 3412.8646\n",
      "Iteration 2900 : Loss 3410.7295\n",
      "Iteration 2910 : Loss 3408.6073\n",
      "Iteration 2920 : Loss 3406.4978\n",
      "Iteration 2930 : Loss 3404.4009\n",
      "Iteration 2940 : Loss 3402.3164\n",
      "Iteration 2950 : Loss 3400.2443\n",
      "Iteration 2960 : Loss 3398.1844\n",
      "Iteration 2970 : Loss 3396.1366\n",
      "Iteration 2980 : Loss 3394.1009\n",
      "Iteration 2990 : Loss 3392.0770\n",
      "Iteration 3000 : Loss 3390.0650\n",
      "Iteration 3010 : Loss 3388.0646\n",
      "Iteration 3020 : Loss 3386.0758\n",
      "Iteration 3030 : Loss 3384.0985\n",
      "Iteration 3040 : Loss 3382.1326\n",
      "Iteration 3050 : Loss 3380.1779\n",
      "Iteration 3060 : Loss 3378.2345\n",
      "Iteration 3070 : Loss 3376.3020\n",
      "Iteration 3080 : Loss 3374.3806\n",
      "Iteration 3090 : Loss 3372.4701\n",
      "Iteration 3100 : Loss 3370.5703\n",
      "Iteration 3110 : Loss 3368.6812\n",
      "Iteration 3120 : Loss 3366.8028\n",
      "Iteration 3130 : Loss 3364.9348\n",
      "Iteration 3140 : Loss 3363.0773\n",
      "Iteration 3150 : Loss 3361.2301\n",
      "Iteration 3160 : Loss 3359.3931\n",
      "Iteration 3170 : Loss 3357.5663\n",
      "Iteration 3180 : Loss 3355.7496\n",
      "Iteration 3190 : Loss 3353.9428\n",
      "Iteration 3200 : Loss 3352.1459\n",
      "Iteration 3210 : Loss 3350.3589\n",
      "Iteration 3220 : Loss 3348.5816\n",
      "Iteration 3230 : Loss 3346.8140\n",
      "Iteration 3240 : Loss 3345.0559\n",
      "Iteration 3250 : Loss 3343.3073\n",
      "Iteration 3260 : Loss 3341.5681\n",
      "Iteration 3270 : Loss 3339.8383\n",
      "Iteration 3280 : Loss 3338.1178\n",
      "Iteration 3290 : Loss 3336.4064\n",
      "Iteration 3300 : Loss 3334.7042\n",
      "Iteration 3310 : Loss 3333.0109\n",
      "Iteration 3320 : Loss 3331.3267\n",
      "Iteration 3330 : Loss 3329.6514\n",
      "Iteration 3340 : Loss 3327.9848\n",
      "Iteration 3350 : Loss 3326.3271\n",
      "Iteration 3360 : Loss 3324.6780\n",
      "Iteration 3370 : Loss 3323.0376\n",
      "Iteration 3380 : Loss 3321.4057\n",
      "Iteration 3390 : Loss 3319.7822\n",
      "Iteration 3400 : Loss 3318.1672\n",
      "Iteration 3410 : Loss 3316.5606\n",
      "Iteration 3420 : Loss 3314.9622\n",
      "Iteration 3430 : Loss 3313.3720\n",
      "Iteration 3440 : Loss 3311.7901\n",
      "Iteration 3450 : Loss 3310.2162\n",
      "Iteration 3460 : Loss 3308.6503\n",
      "Iteration 3470 : Loss 3307.0924\n",
      "Iteration 3480 : Loss 3305.5424\n",
      "Iteration 3490 : Loss 3304.0003\n",
      "Iteration 3500 : Loss 3302.4659\n",
      "Iteration 3510 : Loss 3300.9393\n",
      "Iteration 3520 : Loss 3299.4204\n",
      "Iteration 3530 : Loss 3297.9091\n",
      "Iteration 3540 : Loss 3296.4053\n",
      "Iteration 3550 : Loss 3294.9091\n",
      "Iteration 3560 : Loss 3293.4203\n",
      "Iteration 3570 : Loss 3291.9389\n",
      "Iteration 3580 : Loss 3290.4648\n",
      "Iteration 3590 : Loss 3288.9980\n",
      "Iteration 3600 : Loss 3287.5384\n",
      "Iteration 3610 : Loss 3286.0860\n",
      "Iteration 3620 : Loss 3284.6408\n",
      "Iteration 3630 : Loss 3283.2026\n",
      "Iteration 3640 : Loss 3281.7714\n",
      "Iteration 3650 : Loss 3280.3472\n",
      "Iteration 3660 : Loss 3278.9300\n",
      "Iteration 3670 : Loss 3277.5196\n",
      "Iteration 3680 : Loss 3276.1160\n",
      "Iteration 3690 : Loss 3274.7192\n",
      "Iteration 3700 : Loss 3273.3291\n",
      "Iteration 3710 : Loss 3271.9457\n",
      "Iteration 3720 : Loss 3270.5689\n",
      "Iteration 3730 : Loss 3269.1987\n",
      "Iteration 3740 : Loss 3267.8351\n",
      "Iteration 3750 : Loss 3266.4779\n",
      "Iteration 3760 : Loss 3265.1272\n",
      "Iteration 3770 : Loss 3263.7829\n",
      "Iteration 3780 : Loss 3262.4450\n",
      "Iteration 3790 : Loss 3261.1133\n",
      "Iteration 3800 : Loss 3259.7879\n",
      "Iteration 3810 : Loss 3258.4688\n",
      "Iteration 3820 : Loss 3257.1558\n",
      "Iteration 3830 : Loss 3255.8490\n",
      "Iteration 3840 : Loss 3254.5483\n",
      "Iteration 3850 : Loss 3253.2536\n",
      "Iteration 3860 : Loss 3251.9650\n",
      "Iteration 3870 : Loss 3250.6823\n",
      "Iteration 3880 : Loss 3249.4055\n",
      "Iteration 3890 : Loss 3248.1347\n",
      "Iteration 3900 : Loss 3246.8697\n",
      "Iteration 3910 : Loss 3245.6105\n",
      "Iteration 3920 : Loss 3244.3571\n",
      "Iteration 3930 : Loss 3243.1095\n",
      "Iteration 3940 : Loss 3241.8675\n",
      "Iteration 3950 : Loss 3240.6312\n",
      "Iteration 3960 : Loss 3239.4006\n",
      "Iteration 3970 : Loss 3238.1755\n",
      "Iteration 3980 : Loss 3236.9560\n",
      "Iteration 3990 : Loss 3235.7420\n",
      "Iteration 4000 : Loss 3234.5335\n",
      "Iteration 4010 : Loss 3233.3304\n",
      "Iteration 4020 : Loss 3232.1327\n",
      "Iteration 4030 : Loss 3230.9404\n",
      "Iteration 4040 : Loss 3229.7535\n",
      "Iteration 4050 : Loss 3228.5719\n",
      "Iteration 4060 : Loss 3227.3955\n",
      "Iteration 4070 : Loss 3226.2243\n",
      "Iteration 4080 : Loss 3225.0584\n",
      "Iteration 4090 : Loss 3223.8977\n",
      "Iteration 4100 : Loss 3222.7421\n",
      "Iteration 4110 : Loss 3221.5915\n",
      "Iteration 4120 : Loss 3220.4461\n",
      "Iteration 4130 : Loss 3219.3057\n",
      "Iteration 4140 : Loss 3218.1703\n",
      "Iteration 4150 : Loss 3217.0400\n",
      "Iteration 4160 : Loss 3215.9145\n",
      "Iteration 4170 : Loss 3214.7940\n",
      "Iteration 4180 : Loss 3213.6783\n",
      "Iteration 4190 : Loss 3212.5676\n",
      "Iteration 4200 : Loss 3211.4616\n",
      "Iteration 4210 : Loss 3210.3604\n",
      "Iteration 4220 : Loss 3209.2641\n",
      "Iteration 4230 : Loss 3208.1724\n",
      "Iteration 4240 : Loss 3207.0855\n",
      "Iteration 4250 : Loss 3206.0032\n",
      "Iteration 4260 : Loss 3204.9256\n",
      "Iteration 4270 : Loss 3203.8527\n",
      "Iteration 4280 : Loss 3202.7843\n",
      "Iteration 4290 : Loss 3201.7205\n",
      "Iteration 4300 : Loss 3200.6612\n",
      "Iteration 4310 : Loss 3199.6065\n",
      "Iteration 4320 : Loss 3198.5562\n",
      "Iteration 4330 : Loss 3197.5104\n",
      "Iteration 4340 : Loss 3196.4691\n",
      "Iteration 4350 : Loss 3195.4321\n",
      "Iteration 4360 : Loss 3194.3996\n",
      "Iteration 4370 : Loss 3193.3714\n",
      "Iteration 4380 : Loss 3192.3475\n",
      "Iteration 4390 : Loss 3191.3280\n",
      "Iteration 4400 : Loss 3190.3127\n",
      "Iteration 4410 : Loss 3189.3017\n",
      "Iteration 4420 : Loss 3188.2949\n",
      "Iteration 4430 : Loss 3187.2923\n",
      "Iteration 4440 : Loss 3186.2939\n",
      "Iteration 4450 : Loss 3185.2997\n",
      "Iteration 4460 : Loss 3184.3096\n",
      "Iteration 4470 : Loss 3183.3236\n",
      "Iteration 4480 : Loss 3182.3417\n",
      "Iteration 4490 : Loss 3181.3639\n",
      "Iteration 4500 : Loss 3180.3901\n",
      "Iteration 4510 : Loss 3179.4204\n",
      "Iteration 4520 : Loss 3178.4546\n",
      "Iteration 4530 : Loss 3177.4928\n",
      "Iteration 4540 : Loss 3176.5350\n",
      "Iteration 4550 : Loss 3175.5811\n",
      "Iteration 4560 : Loss 3174.6311\n",
      "Iteration 4570 : Loss 3173.6850\n",
      "Iteration 4580 : Loss 3172.7427\n",
      "Iteration 4590 : Loss 3171.8043\n",
      "Iteration 4600 : Loss 3170.8697\n",
      "Iteration 4610 : Loss 3169.9390\n",
      "Iteration 4620 : Loss 3169.0120\n",
      "Iteration 4630 : Loss 3168.0887\n",
      "Iteration 4640 : Loss 3167.1692\n",
      "Iteration 4650 : Loss 3166.2535\n",
      "Iteration 4660 : Loss 3165.3414\n",
      "Iteration 4670 : Loss 3164.4330\n",
      "Iteration 4680 : Loss 3163.5282\n",
      "Iteration 4690 : Loss 3162.6271\n",
      "Iteration 4700 : Loss 3161.7297\n",
      "Iteration 4710 : Loss 3160.8358\n",
      "Iteration 4720 : Loss 3159.9455\n",
      "Iteration 4730 : Loss 3159.0587\n",
      "Iteration 4740 : Loss 3158.1755\n",
      "Iteration 4750 : Loss 3157.2959\n",
      "Iteration 4760 : Loss 3156.4197\n",
      "Iteration 4770 : Loss 3155.5470\n",
      "Iteration 4780 : Loss 3154.6778\n",
      "Iteration 4790 : Loss 3153.8120\n",
      "Iteration 4800 : Loss 3152.9497\n",
      "Iteration 4810 : Loss 3152.0908\n",
      "Iteration 4820 : Loss 3151.2353\n",
      "Iteration 4830 : Loss 3150.3831\n",
      "Iteration 4840 : Loss 3149.5344\n",
      "Iteration 4850 : Loss 3148.6889\n",
      "Iteration 4860 : Loss 3147.8468\n",
      "Iteration 4870 : Loss 3147.0080\n",
      "Iteration 4880 : Loss 3146.1725\n",
      "Iteration 4890 : Loss 3145.3402\n",
      "Iteration 4900 : Loss 3144.5113\n",
      "Iteration 4910 : Loss 3143.6855\n",
      "Iteration 4920 : Loss 3142.8630\n",
      "Iteration 4930 : Loss 3142.0437\n",
      "Iteration 4940 : Loss 3141.2276\n",
      "Iteration 4950 : Loss 3140.4146\n",
      "Iteration 4960 : Loss 3139.6048\n",
      "Iteration 4970 : Loss 3138.7982\n",
      "Iteration 4980 : Loss 3137.9947\n",
      "Iteration 4990 : Loss 3137.1943\n",
      "Iteration 5000 : Loss 3136.3970\n",
      "Iteration 5010 : Loss 3135.6028\n",
      "Iteration 5020 : Loss 3134.8116\n",
      "Iteration 5030 : Loss 3134.0235\n",
      "Iteration 5040 : Loss 3133.2384\n",
      "Iteration 5050 : Loss 3132.4564\n",
      "Iteration 5060 : Loss 3131.6773\n",
      "Iteration 5070 : Loss 3130.9013\n",
      "Iteration 5080 : Loss 3130.1282\n",
      "Iteration 5090 : Loss 3129.3581\n",
      "Iteration 5100 : Loss 3128.5909\n",
      "Iteration 5110 : Loss 3127.8267\n",
      "Iteration 5120 : Loss 3127.0653\n",
      "Iteration 5130 : Loss 3126.3069\n",
      "Iteration 5140 : Loss 3125.5514\n",
      "Iteration 5150 : Loss 3124.7987\n",
      "Iteration 5160 : Loss 3124.0489\n",
      "Iteration 5170 : Loss 3123.3020\n",
      "Iteration 5180 : Loss 3122.5579\n",
      "Iteration 5190 : Loss 3121.8166\n",
      "Iteration 5200 : Loss 3121.0781\n",
      "Iteration 5210 : Loss 3120.3424\n",
      "Iteration 5220 : Loss 3119.6095\n",
      "Iteration 5230 : Loss 3118.8793\n",
      "Iteration 5240 : Loss 3118.1519\n",
      "Iteration 5250 : Loss 3117.4273\n",
      "Iteration 5260 : Loss 3116.7054\n",
      "Iteration 5270 : Loss 3115.9861\n",
      "Iteration 5280 : Loss 3115.2696\n",
      "Iteration 5290 : Loss 3114.5558\n",
      "Iteration 5300 : Loss 3113.8447\n",
      "Iteration 5310 : Loss 3113.1362\n",
      "Iteration 5320 : Loss 3112.4303\n",
      "Iteration 5330 : Loss 3111.7271\n",
      "Iteration 5340 : Loss 3111.0266\n",
      "Iteration 5350 : Loss 3110.3286\n",
      "Iteration 5360 : Loss 3109.6333\n",
      "Iteration 5370 : Loss 3108.9405\n",
      "Iteration 5380 : Loss 3108.2503\n",
      "Iteration 5390 : Loss 3107.5627\n",
      "Iteration 5400 : Loss 3106.8776\n",
      "Iteration 5410 : Loss 3106.1951\n",
      "Iteration 5420 : Loss 3105.5151\n",
      "Iteration 5430 : Loss 3104.8376\n",
      "Iteration 5440 : Loss 3104.1626\n",
      "Iteration 5450 : Loss 3103.4902\n",
      "Iteration 5460 : Loss 3102.8202\n",
      "Iteration 5470 : Loss 3102.1527\n",
      "Iteration 5480 : Loss 3101.4876\n",
      "Iteration 5490 : Loss 3100.8250\n",
      "Iteration 5500 : Loss 3100.1649\n",
      "Iteration 5510 : Loss 3099.5071\n",
      "Iteration 5520 : Loss 3098.8518\n",
      "Iteration 5530 : Loss 3098.1989\n",
      "Iteration 5540 : Loss 3097.5484\n",
      "Iteration 5550 : Loss 3096.9002\n",
      "Iteration 5560 : Loss 3096.2545\n",
      "Iteration 5570 : Loss 3095.6111\n",
      "Iteration 5580 : Loss 3094.9701\n",
      "Iteration 5590 : Loss 3094.3314\n",
      "Iteration 5600 : Loss 3093.6950\n",
      "Iteration 5610 : Loss 3093.0610\n",
      "Iteration 5620 : Loss 3092.4292\n",
      "Iteration 5630 : Loss 3091.7998\n",
      "Iteration 5640 : Loss 3091.1727\n",
      "Iteration 5650 : Loss 3090.5478\n",
      "Iteration 5660 : Loss 3089.9252\n",
      "Iteration 5670 : Loss 3089.3049\n",
      "Iteration 5680 : Loss 3088.6869\n",
      "Iteration 5690 : Loss 3088.0710\n",
      "Iteration 5700 : Loss 3087.4574\n",
      "Iteration 5710 : Loss 3086.8461\n",
      "Iteration 5720 : Loss 3086.2369\n",
      "Iteration 5730 : Loss 3085.6299\n",
      "Iteration 5740 : Loss 3085.0252\n",
      "Iteration 5750 : Loss 3084.4226\n",
      "Iteration 5760 : Loss 3083.8222\n",
      "Iteration 5770 : Loss 3083.2239\n",
      "Iteration 5780 : Loss 3082.6278\n",
      "Iteration 5790 : Loss 3082.0339\n",
      "Iteration 5800 : Loss 3081.4421\n",
      "Iteration 5810 : Loss 3080.8524\n",
      "Iteration 5820 : Loss 3080.2648\n",
      "Iteration 5830 : Loss 3079.6794\n",
      "Iteration 5840 : Loss 3079.0960\n",
      "Iteration 5850 : Loss 3078.5148\n",
      "Iteration 5860 : Loss 3077.9356\n",
      "Iteration 5870 : Loss 3077.3585\n",
      "Iteration 5880 : Loss 3076.7834\n",
      "Iteration 5890 : Loss 3076.2105\n",
      "Iteration 5900 : Loss 3075.6395\n",
      "Iteration 5910 : Loss 3075.0706\n",
      "Iteration 5920 : Loss 3074.5038\n",
      "Iteration 5930 : Loss 3073.9389\n",
      "Iteration 5940 : Loss 3073.3761\n",
      "Iteration 5950 : Loss 3072.8152\n",
      "Iteration 5960 : Loss 3072.2564\n",
      "Iteration 5970 : Loss 3071.6996\n",
      "Iteration 5980 : Loss 3071.1447\n",
      "Iteration 5990 : Loss 3070.5918\n",
      "Iteration 6000 : Loss 3070.0409\n",
      "Iteration 6010 : Loss 3069.4919\n",
      "Iteration 6020 : Loss 3068.9448\n",
      "Iteration 6030 : Loss 3068.3997\n",
      "Iteration 6040 : Loss 3067.8566\n",
      "Iteration 6050 : Loss 3067.3153\n",
      "Iteration 6060 : Loss 3066.7760\n",
      "Iteration 6070 : Loss 3066.2386\n",
      "Iteration 6080 : Loss 3065.7031\n",
      "Iteration 6090 : Loss 3065.1694\n",
      "Iteration 6100 : Loss 3064.6377\n",
      "Iteration 6110 : Loss 3064.1078\n",
      "Iteration 6120 : Loss 3063.5798\n",
      "Iteration 6130 : Loss 3063.0536\n",
      "Iteration 6140 : Loss 3062.5293\n",
      "Iteration 6150 : Loss 3062.0069\n",
      "Iteration 6160 : Loss 3061.4863\n",
      "Iteration 6170 : Loss 3060.9675\n",
      "Iteration 6180 : Loss 3060.4505\n",
      "Iteration 6190 : Loss 3059.9354\n",
      "Iteration 6200 : Loss 3059.4220\n",
      "Iteration 6210 : Loss 3058.9105\n",
      "Iteration 6220 : Loss 3058.4007\n",
      "Iteration 6230 : Loss 3057.8928\n",
      "Iteration 6240 : Loss 3057.3866\n",
      "Iteration 6250 : Loss 3056.8822\n",
      "Iteration 6260 : Loss 3056.3795\n",
      "Iteration 6270 : Loss 3055.8786\n",
      "Iteration 6280 : Loss 3055.3795\n",
      "Iteration 6290 : Loss 3054.8820\n",
      "Iteration 6300 : Loss 3054.3864\n",
      "Iteration 6310 : Loss 3053.8924\n",
      "Iteration 6320 : Loss 3053.4002\n",
      "Iteration 6330 : Loss 3052.9097\n",
      "Iteration 6340 : Loss 3052.4209\n",
      "Iteration 6350 : Loss 3051.9338\n",
      "Iteration 6360 : Loss 3051.4484\n",
      "Iteration 6370 : Loss 3050.9647\n",
      "Iteration 6380 : Loss 3050.4827\n",
      "Iteration 6390 : Loss 3050.0023\n",
      "Iteration 6400 : Loss 3049.5236\n",
      "Iteration 6410 : Loss 3049.0466\n",
      "Iteration 6420 : Loss 3048.5712\n",
      "Iteration 6430 : Loss 3048.0974\n",
      "Iteration 6440 : Loss 3047.6254\n",
      "Iteration 6450 : Loss 3047.1549\n",
      "Iteration 6460 : Loss 3046.6861\n",
      "Iteration 6470 : Loss 3046.2189\n",
      "Iteration 6480 : Loss 3045.7533\n",
      "Iteration 6490 : Loss 3045.2893\n",
      "Iteration 6500 : Loss 3044.8269\n",
      "Iteration 6510 : Loss 3044.3661\n",
      "Iteration 6520 : Loss 3043.9069\n",
      "Iteration 6530 : Loss 3043.4493\n",
      "Iteration 6540 : Loss 3042.9933\n",
      "Iteration 6550 : Loss 3042.5388\n",
      "Iteration 6560 : Loss 3042.0859\n",
      "Iteration 6570 : Loss 3041.6346\n",
      "Iteration 6580 : Loss 3041.1848\n",
      "Iteration 6590 : Loss 3040.7365\n",
      "Iteration 6600 : Loss 3040.2898\n",
      "Iteration 6610 : Loss 3039.8447\n",
      "Iteration 6620 : Loss 3039.4010\n",
      "Iteration 6630 : Loss 3038.9589\n",
      "Iteration 6640 : Loss 3038.5183\n",
      "Iteration 6650 : Loss 3038.0792\n",
      "Iteration 6660 : Loss 3037.6417\n",
      "Iteration 6670 : Loss 3037.2056\n",
      "Iteration 6680 : Loss 3036.7710\n",
      "Iteration 6690 : Loss 3036.3379\n",
      "Iteration 6700 : Loss 3035.9063\n",
      "Iteration 6710 : Loss 3035.4761\n",
      "Iteration 6720 : Loss 3035.0475\n",
      "Iteration 6730 : Loss 3034.6203\n",
      "Iteration 6740 : Loss 3034.1945\n",
      "Iteration 6750 : Loss 3033.7702\n",
      "Iteration 6760 : Loss 3033.3474\n",
      "Iteration 6770 : Loss 3032.9260\n",
      "Iteration 6780 : Loss 3032.5060\n",
      "Iteration 6790 : Loss 3032.0875\n",
      "Iteration 6800 : Loss 3031.6704\n",
      "Iteration 6810 : Loss 3031.2547\n",
      "Iteration 6820 : Loss 3030.8404\n",
      "Iteration 6830 : Loss 3030.4276\n",
      "Iteration 6840 : Loss 3030.0161\n",
      "Iteration 6850 : Loss 3029.6061\n",
      "Iteration 6860 : Loss 3029.1974\n",
      "Iteration 6870 : Loss 3028.7901\n",
      "Iteration 6880 : Loss 3028.3842\n",
      "Iteration 6890 : Loss 3027.9797\n",
      "Iteration 6900 : Loss 3027.5766\n",
      "Iteration 6910 : Loss 3027.1748\n",
      "Iteration 6920 : Loss 3026.7744\n",
      "Iteration 6930 : Loss 3026.3754\n",
      "Iteration 6940 : Loss 3025.9777\n",
      "Iteration 6950 : Loss 3025.5813\n",
      "Iteration 6960 : Loss 3025.1863\n",
      "Iteration 6970 : Loss 3024.7926\n",
      "Iteration 6980 : Loss 3024.4003\n",
      "Iteration 6990 : Loss 3024.0093\n",
      "Iteration 7000 : Loss 3023.6196\n",
      "Iteration 7010 : Loss 3023.2312\n",
      "Iteration 7020 : Loss 3022.8441\n",
      "Iteration 7030 : Loss 3022.4584\n",
      "Iteration 7040 : Loss 3022.0739\n",
      "Iteration 7050 : Loss 3021.6908\n",
      "Iteration 7060 : Loss 3021.3089\n",
      "Iteration 7070 : Loss 3020.9283\n",
      "Iteration 7080 : Loss 3020.5490\n",
      "Iteration 7090 : Loss 3020.1710\n",
      "Iteration 7100 : Loss 3019.7943\n",
      "Iteration 7110 : Loss 3019.4188\n",
      "Iteration 7120 : Loss 3019.0446\n",
      "Iteration 7130 : Loss 3018.6717\n",
      "Iteration 7140 : Loss 3018.3000\n",
      "Iteration 7150 : Loss 3017.9295\n",
      "Iteration 7160 : Loss 3017.5603\n",
      "Iteration 7170 : Loss 3017.1923\n",
      "Iteration 7180 : Loss 3016.8256\n",
      "Iteration 7190 : Loss 3016.4601\n",
      "Iteration 7200 : Loss 3016.0959\n",
      "Iteration 7210 : Loss 3015.7328\n",
      "Iteration 7220 : Loss 3015.3710\n",
      "Iteration 7230 : Loss 3015.0104\n",
      "Iteration 7240 : Loss 3014.6510\n",
      "Iteration 7250 : Loss 3014.2928\n",
      "Iteration 7260 : Loss 3013.9358\n",
      "Iteration 7270 : Loss 3013.5799\n",
      "Iteration 7280 : Loss 3013.2253\n",
      "Iteration 7290 : Loss 3012.8719\n",
      "Iteration 7300 : Loss 3012.5197\n",
      "Iteration 7310 : Loss 3012.1686\n",
      "Iteration 7320 : Loss 3011.8187\n",
      "Iteration 7330 : Loss 3011.4700\n",
      "Iteration 7340 : Loss 3011.1224\n",
      "Iteration 7350 : Loss 3010.7760\n",
      "Iteration 7360 : Loss 3010.4307\n",
      "Iteration 7370 : Loss 3010.0866\n",
      "Iteration 7380 : Loss 3009.7437\n",
      "Iteration 7390 : Loss 3009.4019\n",
      "Iteration 7400 : Loss 3009.0612\n",
      "Iteration 7410 : Loss 3008.7217\n",
      "Iteration 7420 : Loss 3008.3833\n",
      "Iteration 7430 : Loss 3008.0460\n",
      "Iteration 7440 : Loss 3007.7099\n",
      "Iteration 7450 : Loss 3007.3749\n",
      "Iteration 7460 : Loss 3007.0409\n",
      "Iteration 7470 : Loss 3006.7081\n",
      "Iteration 7480 : Loss 3006.3764\n",
      "Iteration 7490 : Loss 3006.0458\n",
      "Iteration 7500 : Loss 3005.7163\n",
      "Iteration 7510 : Loss 3005.3879\n",
      "Iteration 7520 : Loss 3005.0606\n",
      "Iteration 7530 : Loss 3004.7344\n",
      "Iteration 7540 : Loss 3004.4093\n",
      "Iteration 7550 : Loss 3004.0852\n",
      "Iteration 7560 : Loss 3003.7622\n",
      "Iteration 7570 : Loss 3003.4403\n",
      "Iteration 7580 : Loss 3003.1194\n",
      "Iteration 7590 : Loss 3002.7996\n",
      "Iteration 7600 : Loss 3002.4809\n",
      "Iteration 7610 : Loss 3002.1632\n",
      "Iteration 7620 : Loss 3001.8466\n",
      "Iteration 7630 : Loss 3001.5310\n",
      "Iteration 7640 : Loss 3001.2165\n",
      "Iteration 7650 : Loss 3000.9030\n",
      "Iteration 7660 : Loss 3000.5906\n",
      "Iteration 7670 : Loss 3000.2791\n",
      "Iteration 7680 : Loss 2999.9687\n",
      "Iteration 7690 : Loss 2999.6594\n",
      "Iteration 7700 : Loss 2999.3510\n",
      "Iteration 7710 : Loss 2999.0437\n",
      "Iteration 7720 : Loss 2998.7374\n",
      "Iteration 7730 : Loss 2998.4321\n",
      "Iteration 7740 : Loss 2998.1278\n",
      "Iteration 7750 : Loss 2997.8245\n",
      "Iteration 7760 : Loss 2997.5222\n",
      "Iteration 7770 : Loss 2997.2209\n",
      "Iteration 7780 : Loss 2996.9206\n",
      "Iteration 7790 : Loss 2996.6213\n",
      "Iteration 7800 : Loss 2996.3230\n",
      "Iteration 7810 : Loss 2996.0256\n",
      "Iteration 7820 : Loss 2995.7292\n",
      "Iteration 7830 : Loss 2995.4338\n",
      "Iteration 7840 : Loss 2995.1394\n",
      "Iteration 7850 : Loss 2994.8460\n",
      "Iteration 7860 : Loss 2994.5535\n",
      "Iteration 7870 : Loss 2994.2619\n",
      "Iteration 7880 : Loss 2993.9714\n",
      "Iteration 7890 : Loss 2993.6818\n",
      "Iteration 7900 : Loss 2993.3931\n",
      "Iteration 7910 : Loss 2993.1054\n",
      "Iteration 7920 : Loss 2992.8186\n",
      "Iteration 7930 : Loss 2992.5328\n",
      "Iteration 7940 : Loss 2992.2479\n",
      "Iteration 7950 : Loss 2991.9639\n",
      "Iteration 7960 : Loss 2991.6809\n",
      "Iteration 7970 : Loss 2991.3988\n",
      "Iteration 7980 : Loss 2991.1176\n",
      "Iteration 7990 : Loss 2990.8373\n",
      "Iteration 8000 : Loss 2990.5580\n",
      "Iteration 8010 : Loss 2990.2795\n",
      "Iteration 8020 : Loss 2990.0020\n",
      "Iteration 8030 : Loss 2989.7254\n",
      "Iteration 8040 : Loss 2989.4497\n",
      "Iteration 8050 : Loss 2989.1749\n",
      "Iteration 8060 : Loss 2988.9010\n",
      "Iteration 8070 : Loss 2988.6280\n",
      "Iteration 8080 : Loss 2988.3559\n",
      "Iteration 8090 : Loss 2988.0846\n",
      "Iteration 8100 : Loss 2987.8143\n",
      "Iteration 8110 : Loss 2987.5448\n",
      "Iteration 8120 : Loss 2987.2763\n",
      "Iteration 8130 : Loss 2987.0085\n",
      "Iteration 8140 : Loss 2986.7417\n",
      "Iteration 8150 : Loss 2986.4757\n",
      "Iteration 8160 : Loss 2986.2106\n",
      "Iteration 8170 : Loss 2985.9464\n",
      "Iteration 8180 : Loss 2985.6830\n",
      "Iteration 8190 : Loss 2985.4205\n",
      "Iteration 8200 : Loss 2985.1589\n",
      "Iteration 8210 : Loss 2984.8981\n",
      "Iteration 8220 : Loss 2984.6381\n",
      "Iteration 8230 : Loss 2984.3790\n",
      "Iteration 8240 : Loss 2984.1207\n",
      "Iteration 8250 : Loss 2983.8633\n",
      "Iteration 8260 : Loss 2983.6067\n",
      "Iteration 8270 : Loss 2983.3509\n",
      "Iteration 8280 : Loss 2983.0960\n",
      "Iteration 8290 : Loss 2982.8419\n",
      "Iteration 8300 : Loss 2982.5886\n",
      "Iteration 8310 : Loss 2982.3362\n",
      "Iteration 8320 : Loss 2982.0845\n",
      "Iteration 8330 : Loss 2981.8337\n",
      "Iteration 8340 : Loss 2981.5837\n",
      "Iteration 8350 : Loss 2981.3345\n",
      "Iteration 8360 : Loss 2981.0861\n",
      "Iteration 8370 : Loss 2980.8385\n",
      "Iteration 8380 : Loss 2980.5918\n",
      "Iteration 8390 : Loss 2980.3458\n",
      "Iteration 8400 : Loss 2980.1006\n",
      "Iteration 8410 : Loss 2979.8562\n",
      "Iteration 8420 : Loss 2979.6126\n",
      "Iteration 8430 : Loss 2979.3698\n",
      "Iteration 8440 : Loss 2979.1278\n",
      "Iteration 8450 : Loss 2978.8865\n",
      "Iteration 8460 : Loss 2978.6461\n",
      "Iteration 8470 : Loss 2978.4064\n",
      "Iteration 8480 : Loss 2978.1675\n",
      "Iteration 8490 : Loss 2977.9294\n",
      "Iteration 8500 : Loss 2977.6920\n",
      "Iteration 8510 : Loss 2977.4554\n",
      "Iteration 8520 : Loss 2977.2196\n",
      "Iteration 8530 : Loss 2976.9845\n",
      "Iteration 8540 : Loss 2976.7502\n",
      "Iteration 8550 : Loss 2976.5166\n",
      "Iteration 8560 : Loss 2976.2838\n",
      "Iteration 8570 : Loss 2976.0517\n",
      "Iteration 8580 : Loss 2975.8204\n",
      "Iteration 8590 : Loss 2975.5899\n",
      "Iteration 8600 : Loss 2975.3600\n",
      "Iteration 8610 : Loss 2975.1310\n",
      "Iteration 8620 : Loss 2974.9026\n",
      "Iteration 8630 : Loss 2974.6750\n",
      "Iteration 8640 : Loss 2974.4481\n",
      "Iteration 8650 : Loss 2974.2220\n",
      "Iteration 8660 : Loss 2973.9966\n",
      "Iteration 8670 : Loss 2973.7719\n",
      "Iteration 8680 : Loss 2973.5479\n",
      "Iteration 8690 : Loss 2973.3247\n",
      "Iteration 8700 : Loss 2973.1022\n",
      "Iteration 8710 : Loss 2972.8803\n",
      "Iteration 8720 : Loss 2972.6592\n",
      "Iteration 8730 : Loss 2972.4388\n",
      "Iteration 8740 : Loss 2972.2192\n",
      "Iteration 8750 : Loss 2972.0002\n",
      "Iteration 8760 : Loss 2971.7819\n",
      "Iteration 8770 : Loss 2971.5643\n",
      "Iteration 8780 : Loss 2971.3474\n",
      "Iteration 8790 : Loss 2971.1313\n",
      "Iteration 8800 : Loss 2970.9158\n",
      "Iteration 8810 : Loss 2970.7010\n",
      "Iteration 8820 : Loss 2970.4869\n",
      "Iteration 8830 : Loss 2970.2734\n",
      "Iteration 8840 : Loss 2970.0607\n",
      "Iteration 8850 : Loss 2969.8486\n",
      "Iteration 8860 : Loss 2969.6373\n",
      "Iteration 8870 : Loss 2969.4266\n",
      "Iteration 8880 : Loss 2969.2165\n",
      "Iteration 8890 : Loss 2969.0072\n",
      "Iteration 8900 : Loss 2968.7985\n",
      "Iteration 8910 : Loss 2968.5905\n",
      "Iteration 8920 : Loss 2968.3831\n",
      "Iteration 8930 : Loss 2968.1764\n",
      "Iteration 8940 : Loss 2967.9704\n",
      "Iteration 8950 : Loss 2967.7650\n",
      "Iteration 8960 : Loss 2967.5603\n",
      "Iteration 8970 : Loss 2967.3562\n",
      "Iteration 8980 : Loss 2967.1528\n",
      "Iteration 8990 : Loss 2966.9500\n",
      "Iteration 9000 : Loss 2966.7479\n",
      "Iteration 9010 : Loss 2966.5465\n",
      "Iteration 9020 : Loss 2966.3456\n",
      "Iteration 9030 : Loss 2966.1454\n",
      "Iteration 9040 : Loss 2965.9459\n",
      "Iteration 9050 : Loss 2965.7470\n",
      "Iteration 9060 : Loss 2965.5487\n",
      "Iteration 9070 : Loss 2965.3510\n",
      "Iteration 9080 : Loss 2965.1540\n",
      "Iteration 9090 : Loss 2964.9576\n",
      "Iteration 9100 : Loss 2964.7619\n",
      "Iteration 9110 : Loss 2964.5667\n",
      "Iteration 9120 : Loss 2964.3722\n",
      "Iteration 9130 : Loss 2964.1783\n",
      "Iteration 9140 : Loss 2963.9850\n",
      "Iteration 9150 : Loss 2963.7923\n",
      "Iteration 9160 : Loss 2963.6003\n",
      "Iteration 9170 : Loss 2963.4088\n",
      "Iteration 9180 : Loss 2963.2180\n",
      "Iteration 9190 : Loss 2963.0277\n",
      "Iteration 9200 : Loss 2962.8381\n",
      "Iteration 9210 : Loss 2962.6491\n",
      "Iteration 9220 : Loss 2962.4606\n",
      "Iteration 9230 : Loss 2962.2728\n",
      "Iteration 9240 : Loss 2962.0856\n",
      "Iteration 9250 : Loss 2961.8989\n",
      "Iteration 9260 : Loss 2961.7129\n",
      "Iteration 9270 : Loss 2961.5274\n",
      "Iteration 9280 : Loss 2961.3425\n",
      "Iteration 9290 : Loss 2961.1582\n",
      "Iteration 9300 : Loss 2960.9745\n",
      "Iteration 9310 : Loss 2960.7914\n",
      "Iteration 9320 : Loss 2960.6089\n",
      "Iteration 9330 : Loss 2960.4269\n",
      "Iteration 9340 : Loss 2960.2455\n",
      "Iteration 9350 : Loss 2960.0647\n",
      "Iteration 9360 : Loss 2959.8844\n",
      "Iteration 9370 : Loss 2959.7048\n",
      "Iteration 9380 : Loss 2959.5257\n",
      "Iteration 9390 : Loss 2959.3471\n",
      "Iteration 9400 : Loss 2959.1692\n",
      "Iteration 9410 : Loss 2958.9917\n",
      "Iteration 9420 : Loss 2958.8149\n",
      "Iteration 9430 : Loss 2958.6386\n",
      "Iteration 9440 : Loss 2958.4629\n",
      "Iteration 9450 : Loss 2958.2877\n",
      "Iteration 9460 : Loss 2958.1130\n",
      "Iteration 9470 : Loss 2957.9390\n",
      "Iteration 9480 : Loss 2957.7654\n",
      "Iteration 9490 : Loss 2957.5925\n",
      "Iteration 9500 : Loss 2957.4200\n",
      "Iteration 9510 : Loss 2957.2481\n",
      "Iteration 9520 : Loss 2957.0768\n",
      "Iteration 9530 : Loss 2956.9060\n",
      "Iteration 9540 : Loss 2956.7357\n",
      "Iteration 9550 : Loss 2956.5660\n",
      "Iteration 9560 : Loss 2956.3967\n",
      "Iteration 9570 : Loss 2956.2281\n",
      "Iteration 9580 : Loss 2956.0599\n",
      "Iteration 9590 : Loss 2955.8923\n",
      "Iteration 9600 : Loss 2955.7252\n",
      "Iteration 9610 : Loss 2955.5587\n",
      "Iteration 9620 : Loss 2955.3927\n",
      "Iteration 9630 : Loss 2955.2271\n",
      "Iteration 9640 : Loss 2955.0621\n",
      "Iteration 9650 : Loss 2954.8977\n",
      "Iteration 9660 : Loss 2954.7337\n",
      "Iteration 9670 : Loss 2954.5703\n",
      "Iteration 9680 : Loss 2954.4073\n",
      "Iteration 9690 : Loss 2954.2449\n",
      "Iteration 9700 : Loss 2954.0830\n",
      "Iteration 9710 : Loss 2953.9216\n",
      "Iteration 9720 : Loss 2953.7607\n",
      "Iteration 9730 : Loss 2953.6003\n",
      "Iteration 9740 : Loss 2953.4404\n",
      "Iteration 9750 : Loss 2953.2811\n",
      "Iteration 9760 : Loss 2953.1222\n",
      "Iteration 9770 : Loss 2952.9638\n",
      "Iteration 9780 : Loss 2952.8059\n",
      "Iteration 9790 : Loss 2952.6485\n",
      "Iteration 9800 : Loss 2952.4916\n",
      "Iteration 9810 : Loss 2952.3352\n",
      "Iteration 9820 : Loss 2952.1792\n",
      "Iteration 9830 : Loss 2952.0238\n",
      "Iteration 9840 : Loss 2951.8689\n",
      "Iteration 9850 : Loss 2951.7144\n",
      "Iteration 9860 : Loss 2951.5604\n",
      "Iteration 9870 : Loss 2951.4069\n",
      "Iteration 9880 : Loss 2951.2539\n",
      "Iteration 9890 : Loss 2951.1013\n",
      "Iteration 9900 : Loss 2950.9493\n",
      "Iteration 9910 : Loss 2950.7977\n",
      "Iteration 9920 : Loss 2950.6466\n",
      "Iteration 9930 : Loss 2950.4959\n",
      "Iteration 9940 : Loss 2950.3457\n",
      "Iteration 9950 : Loss 2950.1960\n",
      "Iteration 9960 : Loss 2950.0468\n",
      "Iteration 9970 : Loss 2949.8980\n",
      "Iteration 9980 : Loss 2949.7497\n",
      "Iteration 9990 : Loss 2949.6018\n",
      "Iteration 10000 : Loss 2949.4544\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i in range(1, 10001):\n",
    "    dW, db = gradient(X_train, W, b, y_train)\n",
    "    W -= LEARNING_RATE * dW\n",
    "    b -= LEARNING_RATE * db\n",
    "    L = loss(X_train, W, b, y_train)\n",
    "    losses.append(L)\n",
    "    if i % 10 == 0:\n",
    "        print(\"Iteration %d : Loss %0.4f\" %(i,L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b7e17a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bedb54f",
   "metadata": {},
   "source": [
    "# 8. test 데이터에 대한 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2890c9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2867.2562203745565"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model(X_test,W, b)\n",
    "mse1 = loss(X_test,W, b, y_test)\n",
    "mse1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773eb0a",
   "metadata": {},
   "source": [
    "# 9. 정답 데이터와 예측 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19df3a81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test[:,0], y_test, c = 'r')\n",
    "plt.scatter(X_test[:,0], prediction, c = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5feba05",
   "metadata": {},
   "source": [
    "-끝-\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaec383",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f200b6",
   "metadata": {},
   "source": [
    "## 실험 - 입력 데이터 X 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8f67f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [4,5,6,7,8,9]\n",
    "re_X = np.delete(X,index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4f47a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621,  0.02187235],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, -0.02632783],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, -0.00567061],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626,  0.01728186],\n",
       "       [-0.04547248, -0.04464164,  0.03906215,  0.00121513],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , -0.08141377]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "434a3a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re_X_train shape :  (353, 4) re_y_train shape  :  (353,)\n",
      "re_X_test shape  :  (89, 4) re_y_test shape  :  (89,)\n"
     ]
    }
   ],
   "source": [
    "re_X_train, re_X_test, re_y_train, re_y_test = train_test_split(re_X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(\"re_X_train shape : \", re_X_train.shape,\"re_y_train shape  : \", re_y_train.shape)\n",
    "\n",
    "print(\"re_X_test shape  : \", re_X_test.shape,\"re_y_test shape  : \", re_y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dc997e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 W, b\n",
    "re_W = np.random.rand(4)\n",
    "re_b = np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89d12202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 함수\n",
    "def model(X, W, b):\n",
    "    predictions = 0\n",
    "    for i in range(4):\n",
    "        predictions += X[:, i] * W[i]\n",
    "    predictions += b\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31f9d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE 함수\n",
    "def MSE(a, b):\n",
    "    mse = ((a-b)**2).mean() # 두 값의 차이의 제곱의 평균\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22c3eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 함수를 MSE 함수로 정의\n",
    "def loss(X, W, b, y):\n",
    "    predictions = model(X, W, b)\n",
    "    L = MSE(predictions, y)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd7f3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, W, b, y):\n",
    "    N = len(W)\n",
    "    y_pred = model(X, W, b)\n",
    "    dW = 1/N * 2 * X.T.dot(y_pred - y)\n",
    "    db = 2 * (y_pred - y).mean()\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf7cc955",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b58b7205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 : Loss 28568.5210\n",
      "Iteration 20 : Loss 27648.1286\n",
      "Iteration 30 : Loss 26763.1992\n",
      "Iteration 40 : Loss 25912.3478\n",
      "Iteration 50 : Loss 25094.2439\n",
      "Iteration 60 : Loss 24307.6088\n",
      "Iteration 70 : Loss 23551.2144\n",
      "Iteration 80 : Loss 22823.8803\n",
      "Iteration 90 : Loss 22124.4727\n",
      "Iteration 100 : Loss 21451.9021\n",
      "Iteration 110 : Loss 20805.1218\n",
      "Iteration 120 : Loss 20183.1259\n",
      "Iteration 130 : Loss 19584.9482\n",
      "Iteration 140 : Loss 19009.6601\n",
      "Iteration 150 : Loss 18456.3697\n",
      "Iteration 160 : Loss 17924.2198\n",
      "Iteration 170 : Loss 17412.3869\n",
      "Iteration 180 : Loss 16920.0797\n",
      "Iteration 190 : Loss 16446.5379\n",
      "Iteration 200 : Loss 15991.0311\n",
      "Iteration 210 : Loss 15552.8573\n",
      "Iteration 220 : Loss 15131.3422\n",
      "Iteration 230 : Loss 14725.8379\n",
      "Iteration 240 : Loss 14335.7216\n",
      "Iteration 250 : Loss 13960.3953\n",
      "Iteration 260 : Loss 13599.2841\n",
      "Iteration 270 : Loss 13251.8357\n",
      "Iteration 280 : Loss 12917.5194\n",
      "Iteration 290 : Loss 12595.8254\n",
      "Iteration 300 : Loss 12286.2637\n",
      "Iteration 310 : Loss 11988.3635\n",
      "Iteration 320 : Loss 11701.6726\n",
      "Iteration 330 : Loss 11425.7561\n",
      "Iteration 340 : Loss 11160.1966\n",
      "Iteration 350 : Loss 10904.5927\n",
      "Iteration 360 : Loss 10658.5588\n",
      "Iteration 370 : Loss 10421.7243\n",
      "Iteration 380 : Loss 10193.7333\n",
      "Iteration 390 : Loss 9974.2436\n",
      "Iteration 400 : Loss 9762.9264\n",
      "Iteration 410 : Loss 9559.4660\n",
      "Iteration 420 : Loss 9363.5586\n",
      "Iteration 430 : Loss 9174.9128\n",
      "Iteration 440 : Loss 8993.2481\n",
      "Iteration 450 : Loss 8818.2952\n",
      "Iteration 460 : Loss 8649.7954\n",
      "Iteration 470 : Loss 8487.4999\n",
      "Iteration 480 : Loss 8331.1697\n",
      "Iteration 490 : Loss 8180.5752\n",
      "Iteration 500 : Loss 8035.4956\n",
      "Iteration 510 : Loss 7895.7189\n",
      "Iteration 520 : Loss 7761.0413\n",
      "Iteration 530 : Loss 7631.2669\n",
      "Iteration 540 : Loss 7506.2075\n",
      "Iteration 550 : Loss 7385.6822\n",
      "Iteration 560 : Loss 7269.5172\n",
      "Iteration 570 : Loss 7157.5455\n",
      "Iteration 580 : Loss 7049.6065\n",
      "Iteration 590 : Loss 6945.5459\n",
      "Iteration 600 : Loss 6845.2155\n",
      "Iteration 610 : Loss 6748.4728\n",
      "Iteration 620 : Loss 6655.1808\n",
      "Iteration 630 : Loss 6565.2079\n",
      "Iteration 640 : Loss 6478.4277\n",
      "Iteration 650 : Loss 6394.7185\n",
      "Iteration 660 : Loss 6313.9636\n",
      "Iteration 670 : Loss 6236.0506\n",
      "Iteration 680 : Loss 6160.8716\n",
      "Iteration 690 : Loss 6088.3228\n",
      "Iteration 700 : Loss 6018.3047\n",
      "Iteration 710 : Loss 5950.7213\n",
      "Iteration 720 : Loss 5885.4805\n",
      "Iteration 730 : Loss 5822.4938\n",
      "Iteration 740 : Loss 5761.6761\n",
      "Iteration 750 : Loss 5702.9457\n",
      "Iteration 760 : Loss 5646.2238\n",
      "Iteration 770 : Loss 5591.4350\n",
      "Iteration 780 : Loss 5538.5065\n",
      "Iteration 790 : Loss 5487.3686\n",
      "Iteration 800 : Loss 5437.9541\n",
      "Iteration 810 : Loss 5390.1985\n",
      "Iteration 820 : Loss 5344.0398\n",
      "Iteration 830 : Loss 5299.4183\n",
      "Iteration 840 : Loss 5256.2768\n",
      "Iteration 850 : Loss 5214.5600\n",
      "Iteration 860 : Loss 5174.2151\n",
      "Iteration 870 : Loss 5135.1911\n",
      "Iteration 880 : Loss 5097.4390\n",
      "Iteration 890 : Loss 5060.9117\n",
      "Iteration 900 : Loss 5025.5641\n",
      "Iteration 910 : Loss 4991.3525\n",
      "Iteration 920 : Loss 4958.2351\n",
      "Iteration 930 : Loss 4926.1717\n",
      "Iteration 940 : Loss 4895.1236\n",
      "Iteration 950 : Loss 4865.0537\n",
      "Iteration 960 : Loss 4835.9260\n",
      "Iteration 970 : Loss 4807.7063\n",
      "Iteration 980 : Loss 4780.3615\n",
      "Iteration 990 : Loss 4753.8598\n",
      "Iteration 1000 : Loss 4728.1705\n",
      "Iteration 1010 : Loss 4703.2643\n",
      "Iteration 1020 : Loss 4679.1129\n",
      "Iteration 1030 : Loss 4655.6891\n",
      "Iteration 1040 : Loss 4632.9667\n",
      "Iteration 1050 : Loss 4610.9205\n",
      "Iteration 1060 : Loss 4589.5264\n",
      "Iteration 1070 : Loss 4568.7610\n",
      "Iteration 1080 : Loss 4548.6020\n",
      "Iteration 1090 : Loss 4529.0279\n",
      "Iteration 1100 : Loss 4510.0178\n",
      "Iteration 1110 : Loss 4491.5519\n",
      "Iteration 1120 : Loss 4473.6109\n",
      "Iteration 1130 : Loss 4456.1766\n",
      "Iteration 1140 : Loss 4439.2310\n",
      "Iteration 1150 : Loss 4422.7571\n",
      "Iteration 1160 : Loss 4406.7385\n",
      "Iteration 1170 : Loss 4391.1593\n",
      "Iteration 1180 : Loss 4376.0044\n",
      "Iteration 1190 : Loss 4361.2591\n",
      "Iteration 1200 : Loss 4346.9094\n",
      "Iteration 1210 : Loss 4332.9416\n",
      "Iteration 1220 : Loss 4319.3427\n",
      "Iteration 1230 : Loss 4306.1002\n",
      "Iteration 1240 : Loss 4293.2020\n",
      "Iteration 1250 : Loss 4280.6364\n",
      "Iteration 1260 : Loss 4268.3922\n",
      "Iteration 1270 : Loss 4256.4587\n",
      "Iteration 1280 : Loss 4244.8254\n",
      "Iteration 1290 : Loss 4233.4825\n",
      "Iteration 1300 : Loss 4222.4202\n",
      "Iteration 1310 : Loss 4211.6292\n",
      "Iteration 1320 : Loss 4201.1008\n",
      "Iteration 1330 : Loss 4190.8263\n",
      "Iteration 1340 : Loss 4180.7974\n",
      "Iteration 1350 : Loss 4171.0061\n",
      "Iteration 1360 : Loss 4161.4448\n",
      "Iteration 1370 : Loss 4152.1061\n",
      "Iteration 1380 : Loss 4142.9828\n",
      "Iteration 1390 : Loss 4134.0682\n",
      "Iteration 1400 : Loss 4125.3555\n",
      "Iteration 1410 : Loss 4116.8385\n",
      "Iteration 1420 : Loss 4108.5110\n",
      "Iteration 1430 : Loss 4100.3671\n",
      "Iteration 1440 : Loss 4092.4010\n",
      "Iteration 1450 : Loss 4084.6074\n",
      "Iteration 1460 : Loss 4076.9809\n",
      "Iteration 1470 : Loss 4069.5164\n",
      "Iteration 1480 : Loss 4062.2090\n",
      "Iteration 1490 : Loss 4055.0540\n",
      "Iteration 1500 : Loss 4048.0467\n",
      "Iteration 1510 : Loss 4041.1828\n",
      "Iteration 1520 : Loss 4034.4581\n",
      "Iteration 1530 : Loss 4027.8684\n",
      "Iteration 1540 : Loss 4021.4097\n",
      "Iteration 1550 : Loss 4015.0784\n",
      "Iteration 1560 : Loss 4008.8706\n",
      "Iteration 1570 : Loss 4002.7829\n",
      "Iteration 1580 : Loss 3996.8117\n",
      "Iteration 1590 : Loss 3990.9539\n",
      "Iteration 1600 : Loss 3985.2062\n",
      "Iteration 1610 : Loss 3979.5656\n",
      "Iteration 1620 : Loss 3974.0290\n",
      "Iteration 1630 : Loss 3968.5937\n",
      "Iteration 1640 : Loss 3963.2568\n",
      "Iteration 1650 : Loss 3958.0156\n",
      "Iteration 1660 : Loss 3952.8676\n",
      "Iteration 1670 : Loss 3947.8103\n",
      "Iteration 1680 : Loss 3942.8413\n",
      "Iteration 1690 : Loss 3937.9583\n",
      "Iteration 1700 : Loss 3933.1589\n",
      "Iteration 1710 : Loss 3928.4411\n",
      "Iteration 1720 : Loss 3923.8026\n",
      "Iteration 1730 : Loss 3919.2416\n",
      "Iteration 1740 : Loss 3914.7560\n",
      "Iteration 1750 : Loss 3910.3440\n",
      "Iteration 1760 : Loss 3906.0036\n",
      "Iteration 1770 : Loss 3901.7332\n",
      "Iteration 1780 : Loss 3897.5310\n",
      "Iteration 1790 : Loss 3893.3953\n",
      "Iteration 1800 : Loss 3889.3246\n",
      "Iteration 1810 : Loss 3885.3172\n",
      "Iteration 1820 : Loss 3881.3718\n",
      "Iteration 1830 : Loss 3877.4867\n",
      "Iteration 1840 : Loss 3873.6607\n",
      "Iteration 1850 : Loss 3869.8923\n",
      "Iteration 1860 : Loss 3866.1802\n",
      "Iteration 1870 : Loss 3862.5232\n",
      "Iteration 1880 : Loss 3858.9200\n",
      "Iteration 1890 : Loss 3855.3694\n",
      "Iteration 1900 : Loss 3851.8702\n",
      "Iteration 1910 : Loss 3848.4213\n",
      "Iteration 1920 : Loss 3845.0216\n",
      "Iteration 1930 : Loss 3841.6701\n",
      "Iteration 1940 : Loss 3838.3657\n",
      "Iteration 1950 : Loss 3835.1074\n",
      "Iteration 1960 : Loss 3831.8943\n",
      "Iteration 1970 : Loss 3828.7253\n",
      "Iteration 1980 : Loss 3825.5997\n",
      "Iteration 1990 : Loss 3822.5165\n",
      "Iteration 2000 : Loss 3819.4748\n",
      "Iteration 2010 : Loss 3816.4738\n",
      "Iteration 2020 : Loss 3813.5128\n",
      "Iteration 2030 : Loss 3810.5909\n",
      "Iteration 2040 : Loss 3807.7073\n",
      "Iteration 2050 : Loss 3804.8613\n",
      "Iteration 2060 : Loss 3802.0522\n",
      "Iteration 2070 : Loss 3799.2793\n",
      "Iteration 2080 : Loss 3796.5419\n",
      "Iteration 2090 : Loss 3793.8394\n",
      "Iteration 2100 : Loss 3791.1710\n",
      "Iteration 2110 : Loss 3788.5362\n",
      "Iteration 2120 : Loss 3785.9343\n",
      "Iteration 2130 : Loss 3783.3648\n",
      "Iteration 2140 : Loss 3780.8271\n",
      "Iteration 2150 : Loss 3778.3206\n",
      "Iteration 2160 : Loss 3775.8447\n",
      "Iteration 2170 : Loss 3773.3990\n",
      "Iteration 2180 : Loss 3770.9829\n",
      "Iteration 2190 : Loss 3768.5959\n",
      "Iteration 2200 : Loss 3766.2374\n",
      "Iteration 2210 : Loss 3763.9071\n",
      "Iteration 2220 : Loss 3761.6045\n",
      "Iteration 2230 : Loss 3759.3290\n",
      "Iteration 2240 : Loss 3757.0802\n",
      "Iteration 2250 : Loss 3754.8578\n",
      "Iteration 2260 : Loss 3752.6613\n",
      "Iteration 2270 : Loss 3750.4902\n",
      "Iteration 2280 : Loss 3748.3441\n",
      "Iteration 2290 : Loss 3746.2227\n",
      "Iteration 2300 : Loss 3744.1256\n",
      "Iteration 2310 : Loss 3742.0524\n",
      "Iteration 2320 : Loss 3740.0027\n",
      "Iteration 2330 : Loss 3737.9762\n",
      "Iteration 2340 : Loss 3735.9724\n",
      "Iteration 2350 : Loss 3733.9912\n",
      "Iteration 2360 : Loss 3732.0320\n",
      "Iteration 2370 : Loss 3730.0947\n",
      "Iteration 2380 : Loss 3728.1788\n",
      "Iteration 2390 : Loss 3726.2841\n",
      "Iteration 2400 : Loss 3724.4102\n",
      "Iteration 2410 : Loss 3722.5569\n",
      "Iteration 2420 : Loss 3720.7238\n",
      "Iteration 2430 : Loss 3718.9107\n",
      "Iteration 2440 : Loss 3717.1173\n",
      "Iteration 2450 : Loss 3715.3432\n",
      "Iteration 2460 : Loss 3713.5883\n",
      "Iteration 2470 : Loss 3711.8522\n",
      "Iteration 2480 : Loss 3710.1348\n",
      "Iteration 2490 : Loss 3708.4356\n",
      "Iteration 2500 : Loss 3706.7546\n",
      "Iteration 2510 : Loss 3705.0914\n",
      "Iteration 2520 : Loss 3703.4458\n",
      "Iteration 2530 : Loss 3701.8176\n",
      "Iteration 2540 : Loss 3700.2065\n",
      "Iteration 2550 : Loss 3698.6123\n",
      "Iteration 2560 : Loss 3697.0348\n",
      "Iteration 2570 : Loss 3695.4738\n",
      "Iteration 2580 : Loss 3693.9290\n",
      "Iteration 2590 : Loss 3692.4003\n",
      "Iteration 2600 : Loss 3690.8873\n",
      "Iteration 2610 : Loss 3689.3900\n",
      "Iteration 2620 : Loss 3687.9082\n",
      "Iteration 2630 : Loss 3686.4415\n",
      "Iteration 2640 : Loss 3684.9899\n",
      "Iteration 2650 : Loss 3683.5531\n",
      "Iteration 2660 : Loss 3682.1310\n",
      "Iteration 2670 : Loss 3680.7234\n",
      "Iteration 2680 : Loss 3679.3300\n",
      "Iteration 2690 : Loss 3677.9508\n",
      "Iteration 2700 : Loss 3676.5855\n",
      "Iteration 2710 : Loss 3675.2340\n",
      "Iteration 2720 : Loss 3673.8961\n",
      "Iteration 2730 : Loss 3672.5717\n",
      "Iteration 2740 : Loss 3671.2605\n",
      "Iteration 2750 : Loss 3669.9624\n",
      "Iteration 2760 : Loss 3668.6773\n",
      "Iteration 2770 : Loss 3667.4050\n",
      "Iteration 2780 : Loss 3666.1453\n",
      "Iteration 2790 : Loss 3664.8981\n",
      "Iteration 2800 : Loss 3663.6633\n",
      "Iteration 2810 : Loss 3662.4407\n",
      "Iteration 2820 : Loss 3661.2302\n",
      "Iteration 2830 : Loss 3660.0316\n",
      "Iteration 2840 : Loss 3658.8447\n",
      "Iteration 2850 : Loss 3657.6695\n",
      "Iteration 2860 : Loss 3656.5058\n",
      "Iteration 2870 : Loss 3655.3535\n",
      "Iteration 2880 : Loss 3654.2125\n",
      "Iteration 2890 : Loss 3653.0825\n",
      "Iteration 2900 : Loss 3651.9636\n",
      "Iteration 2910 : Loss 3650.8555\n",
      "Iteration 2920 : Loss 3649.7581\n",
      "Iteration 2930 : Loss 3648.6714\n",
      "Iteration 2940 : Loss 3647.5952\n",
      "Iteration 2950 : Loss 3646.5293\n",
      "Iteration 2960 : Loss 3645.4737\n",
      "Iteration 2970 : Loss 3644.4283\n",
      "Iteration 2980 : Loss 3643.3929\n",
      "Iteration 2990 : Loss 3642.3674\n",
      "Iteration 3000 : Loss 3641.3518\n",
      "Iteration 3010 : Loss 3640.3458\n",
      "Iteration 3020 : Loss 3639.3494\n",
      "Iteration 3030 : Loss 3638.3626\n",
      "Iteration 3040 : Loss 3637.3851\n",
      "Iteration 3050 : Loss 3636.4169\n",
      "Iteration 3060 : Loss 3635.4579\n",
      "Iteration 3070 : Loss 3634.5080\n",
      "Iteration 3080 : Loss 3633.5670\n",
      "Iteration 3090 : Loss 3632.6350\n",
      "Iteration 3100 : Loss 3631.7117\n",
      "Iteration 3110 : Loss 3630.7971\n",
      "Iteration 3120 : Loss 3629.8912\n",
      "Iteration 3130 : Loss 3628.9937\n",
      "Iteration 3140 : Loss 3628.1047\n",
      "Iteration 3150 : Loss 3627.2239\n",
      "Iteration 3160 : Loss 3626.3515\n",
      "Iteration 3170 : Loss 3625.4871\n",
      "Iteration 3180 : Loss 3624.6309\n",
      "Iteration 3190 : Loss 3623.7826\n",
      "Iteration 3200 : Loss 3622.9422\n",
      "Iteration 3210 : Loss 3622.1096\n",
      "Iteration 3220 : Loss 3621.2848\n",
      "Iteration 3230 : Loss 3620.4676\n",
      "Iteration 3240 : Loss 3619.6579\n",
      "Iteration 3250 : Loss 3618.8558\n",
      "Iteration 3260 : Loss 3618.0610\n",
      "Iteration 3270 : Loss 3617.2736\n",
      "Iteration 3280 : Loss 3616.4934\n",
      "Iteration 3290 : Loss 3615.7205\n",
      "Iteration 3300 : Loss 3614.9546\n",
      "Iteration 3310 : Loss 3614.1957\n",
      "Iteration 3320 : Loss 3613.4438\n",
      "Iteration 3330 : Loss 3612.6988\n",
      "Iteration 3340 : Loss 3611.9606\n",
      "Iteration 3350 : Loss 3611.2291\n",
      "Iteration 3360 : Loss 3610.5044\n",
      "Iteration 3370 : Loss 3609.7862\n",
      "Iteration 3380 : Loss 3609.0745\n",
      "Iteration 3390 : Loss 3608.3694\n",
      "Iteration 3400 : Loss 3607.6706\n",
      "Iteration 3410 : Loss 3606.9782\n",
      "Iteration 3420 : Loss 3606.2920\n",
      "Iteration 3430 : Loss 3605.6120\n",
      "Iteration 3440 : Loss 3604.9382\n",
      "Iteration 3450 : Loss 3604.2705\n",
      "Iteration 3460 : Loss 3603.6088\n",
      "Iteration 3470 : Loss 3602.9531\n",
      "Iteration 3480 : Loss 3602.3032\n",
      "Iteration 3490 : Loss 3601.6592\n",
      "Iteration 3500 : Loss 3601.0210\n",
      "Iteration 3510 : Loss 3600.3885\n",
      "Iteration 3520 : Loss 3599.7617\n",
      "Iteration 3530 : Loss 3599.1405\n",
      "Iteration 3540 : Loss 3598.5248\n",
      "Iteration 3550 : Loss 3597.9147\n",
      "Iteration 3560 : Loss 3597.3099\n",
      "Iteration 3570 : Loss 3596.7106\n",
      "Iteration 3580 : Loss 3596.1166\n",
      "Iteration 3590 : Loss 3595.5279\n",
      "Iteration 3600 : Loss 3594.9444\n",
      "Iteration 3610 : Loss 3594.3661\n",
      "Iteration 3620 : Loss 3593.7929\n",
      "Iteration 3630 : Loss 3593.2248\n",
      "Iteration 3640 : Loss 3592.6617\n",
      "Iteration 3650 : Loss 3592.1036\n",
      "Iteration 3660 : Loss 3591.5504\n",
      "Iteration 3670 : Loss 3591.0021\n",
      "Iteration 3680 : Loss 3590.4586\n",
      "Iteration 3690 : Loss 3589.9199\n",
      "Iteration 3700 : Loss 3589.3859\n",
      "Iteration 3710 : Loss 3588.8566\n",
      "Iteration 3720 : Loss 3588.3320\n",
      "Iteration 3730 : Loss 3587.8119\n",
      "Iteration 3740 : Loss 3587.2964\n",
      "Iteration 3750 : Loss 3586.7855\n",
      "Iteration 3760 : Loss 3586.2789\n",
      "Iteration 3770 : Loss 3585.7768\n",
      "Iteration 3780 : Loss 3585.2791\n",
      "Iteration 3790 : Loss 3584.7857\n",
      "Iteration 3800 : Loss 3584.2966\n",
      "Iteration 3810 : Loss 3583.8118\n",
      "Iteration 3820 : Loss 3583.3311\n",
      "Iteration 3830 : Loss 3582.8547\n",
      "Iteration 3840 : Loss 3582.3823\n",
      "Iteration 3850 : Loss 3581.9141\n",
      "Iteration 3860 : Loss 3581.4498\n",
      "Iteration 3870 : Loss 3580.9896\n",
      "Iteration 3880 : Loss 3580.5334\n",
      "Iteration 3890 : Loss 3580.0811\n",
      "Iteration 3900 : Loss 3579.6327\n",
      "Iteration 3910 : Loss 3579.1882\n",
      "Iteration 3920 : Loss 3578.7475\n",
      "Iteration 3930 : Loss 3578.3105\n",
      "Iteration 3940 : Loss 3577.8774\n",
      "Iteration 3950 : Loss 3577.4479\n",
      "Iteration 3960 : Loss 3577.0221\n",
      "Iteration 3970 : Loss 3576.5999\n",
      "Iteration 3980 : Loss 3576.1814\n",
      "Iteration 3990 : Loss 3575.7664\n",
      "Iteration 4000 : Loss 3575.3550\n",
      "Iteration 4010 : Loss 3574.9470\n",
      "Iteration 4020 : Loss 3574.5426\n",
      "Iteration 4030 : Loss 3574.1416\n",
      "Iteration 4040 : Loss 3573.7440\n",
      "Iteration 4050 : Loss 3573.3497\n",
      "Iteration 4060 : Loss 3572.9588\n",
      "Iteration 4070 : Loss 3572.5713\n",
      "Iteration 4080 : Loss 3572.1870\n",
      "Iteration 4090 : Loss 3571.8059\n",
      "Iteration 4100 : Loss 3571.4281\n",
      "Iteration 4110 : Loss 3571.0534\n",
      "Iteration 4120 : Loss 3570.6819\n",
      "Iteration 4130 : Loss 3570.3136\n",
      "Iteration 4140 : Loss 3569.9483\n",
      "Iteration 4150 : Loss 3569.5862\n",
      "Iteration 4160 : Loss 3569.2270\n",
      "Iteration 4170 : Loss 3568.8709\n",
      "Iteration 4180 : Loss 3568.5177\n",
      "Iteration 4190 : Loss 3568.1676\n",
      "Iteration 4200 : Loss 3567.8203\n",
      "Iteration 4210 : Loss 3567.4760\n",
      "Iteration 4220 : Loss 3567.1345\n",
      "Iteration 4230 : Loss 3566.7959\n",
      "Iteration 4240 : Loss 3566.4601\n",
      "Iteration 4250 : Loss 3566.1271\n",
      "Iteration 4260 : Loss 3565.7968\n",
      "Iteration 4270 : Loss 3565.4694\n",
      "Iteration 4280 : Loss 3565.1446\n",
      "Iteration 4290 : Loss 3564.8225\n",
      "Iteration 4300 : Loss 3564.5031\n",
      "Iteration 4310 : Loss 3564.1864\n",
      "Iteration 4320 : Loss 3563.8723\n",
      "Iteration 4330 : Loss 3563.5607\n",
      "Iteration 4340 : Loss 3563.2518\n",
      "Iteration 4350 : Loss 3562.9454\n",
      "Iteration 4360 : Loss 3562.6415\n",
      "Iteration 4370 : Loss 3562.3401\n",
      "Iteration 4380 : Loss 3562.0412\n",
      "Iteration 4390 : Loss 3561.7448\n",
      "Iteration 4400 : Loss 3561.4508\n",
      "Iteration 4410 : Loss 3561.1592\n",
      "Iteration 4420 : Loss 3560.8700\n",
      "Iteration 4430 : Loss 3560.5832\n",
      "Iteration 4440 : Loss 3560.2987\n",
      "Iteration 4450 : Loss 3560.0166\n",
      "Iteration 4460 : Loss 3559.7367\n",
      "Iteration 4470 : Loss 3559.4592\n",
      "Iteration 4480 : Loss 3559.1839\n",
      "Iteration 4490 : Loss 3558.9108\n",
      "Iteration 4500 : Loss 3558.6400\n",
      "Iteration 4510 : Loss 3558.3714\n",
      "Iteration 4520 : Loss 3558.1050\n",
      "Iteration 4530 : Loss 3557.8407\n",
      "Iteration 4540 : Loss 3557.5786\n",
      "Iteration 4550 : Loss 3557.3186\n",
      "Iteration 4560 : Loss 3557.0607\n",
      "Iteration 4570 : Loss 3556.8049\n",
      "Iteration 4580 : Loss 3556.5511\n",
      "Iteration 4590 : Loss 3556.2995\n",
      "Iteration 4600 : Loss 3556.0498\n",
      "Iteration 4610 : Loss 3555.8022\n",
      "Iteration 4620 : Loss 3555.5565\n",
      "Iteration 4630 : Loss 3555.3129\n",
      "Iteration 4640 : Loss 3555.0712\n",
      "Iteration 4650 : Loss 3554.8314\n",
      "Iteration 4660 : Loss 3554.5936\n",
      "Iteration 4670 : Loss 3554.3577\n",
      "Iteration 4680 : Loss 3554.1236\n",
      "Iteration 4690 : Loss 3553.8915\n",
      "Iteration 4700 : Loss 3553.6612\n",
      "Iteration 4710 : Loss 3553.4327\n",
      "Iteration 4720 : Loss 3553.2061\n",
      "Iteration 4730 : Loss 3552.9813\n",
      "Iteration 4740 : Loss 3552.7583\n",
      "Iteration 4750 : Loss 3552.5370\n",
      "Iteration 4760 : Loss 3552.3175\n",
      "Iteration 4770 : Loss 3552.0998\n",
      "Iteration 4780 : Loss 3551.8838\n",
      "Iteration 4790 : Loss 3551.6695\n",
      "Iteration 4800 : Loss 3551.4569\n",
      "Iteration 4810 : Loss 3551.2460\n",
      "Iteration 4820 : Loss 3551.0368\n",
      "Iteration 4830 : Loss 3550.8293\n",
      "Iteration 4840 : Loss 3550.6233\n",
      "Iteration 4850 : Loss 3550.4190\n",
      "Iteration 4860 : Loss 3550.2163\n",
      "Iteration 4870 : Loss 3550.0153\n",
      "Iteration 4880 : Loss 3549.8158\n",
      "Iteration 4890 : Loss 3549.6178\n",
      "Iteration 4900 : Loss 3549.4215\n",
      "Iteration 4910 : Loss 3549.2267\n",
      "Iteration 4920 : Loss 3549.0334\n",
      "Iteration 4930 : Loss 3548.8416\n",
      "Iteration 4940 : Loss 3548.6513\n",
      "Iteration 4950 : Loss 3548.4626\n",
      "Iteration 4960 : Loss 3548.2753\n",
      "Iteration 4970 : Loss 3548.0895\n",
      "Iteration 4980 : Loss 3547.9051\n",
      "Iteration 4990 : Loss 3547.7222\n",
      "Iteration 5000 : Loss 3547.5407\n",
      "Iteration 5010 : Loss 3547.3606\n",
      "Iteration 5020 : Loss 3547.1819\n",
      "Iteration 5030 : Loss 3547.0046\n",
      "Iteration 5040 : Loss 3546.8287\n",
      "Iteration 5050 : Loss 3546.6542\n",
      "Iteration 5060 : Loss 3546.4810\n",
      "Iteration 5070 : Loss 3546.3092\n",
      "Iteration 5080 : Loss 3546.1387\n",
      "Iteration 5090 : Loss 3545.9695\n",
      "Iteration 5100 : Loss 3545.8016\n",
      "Iteration 5110 : Loss 3545.6351\n",
      "Iteration 5120 : Loss 3545.4698\n",
      "Iteration 5130 : Loss 3545.3058\n",
      "Iteration 5140 : Loss 3545.1431\n",
      "Iteration 5150 : Loss 3544.9816\n",
      "Iteration 5160 : Loss 3544.8214\n",
      "Iteration 5170 : Loss 3544.6624\n",
      "Iteration 5180 : Loss 3544.5046\n",
      "Iteration 5190 : Loss 3544.3481\n",
      "Iteration 5200 : Loss 3544.1927\n",
      "Iteration 5210 : Loss 3544.0386\n",
      "Iteration 5220 : Loss 3543.8856\n",
      "Iteration 5230 : Loss 3543.7338\n",
      "Iteration 5240 : Loss 3543.5832\n",
      "Iteration 5250 : Loss 3543.4337\n",
      "Iteration 5260 : Loss 3543.2854\n",
      "Iteration 5270 : Loss 3543.1382\n",
      "Iteration 5280 : Loss 3542.9921\n",
      "Iteration 5290 : Loss 3542.8472\n",
      "Iteration 5300 : Loss 3542.7033\n",
      "Iteration 5310 : Loss 3542.5606\n",
      "Iteration 5320 : Loss 3542.4189\n",
      "Iteration 5330 : Loss 3542.2783\n",
      "Iteration 5340 : Loss 3542.1388\n",
      "Iteration 5350 : Loss 3542.0004\n",
      "Iteration 5360 : Loss 3541.8630\n",
      "Iteration 5370 : Loss 3541.7266\n",
      "Iteration 5380 : Loss 3541.5913\n",
      "Iteration 5390 : Loss 3541.4570\n",
      "Iteration 5400 : Loss 3541.3237\n",
      "Iteration 5410 : Loss 3541.1915\n",
      "Iteration 5420 : Loss 3541.0602\n",
      "Iteration 5430 : Loss 3540.9299\n",
      "Iteration 5440 : Loss 3540.8006\n",
      "Iteration 5450 : Loss 3540.6723\n",
      "Iteration 5460 : Loss 3540.5450\n",
      "Iteration 5470 : Loss 3540.4186\n",
      "Iteration 5480 : Loss 3540.2932\n",
      "Iteration 5490 : Loss 3540.1687\n",
      "Iteration 5500 : Loss 3540.0451\n",
      "Iteration 5510 : Loss 3539.9225\n",
      "Iteration 5520 : Loss 3539.8008\n",
      "Iteration 5530 : Loss 3539.6801\n",
      "Iteration 5540 : Loss 3539.5602\n",
      "Iteration 5550 : Loss 3539.4412\n",
      "Iteration 5560 : Loss 3539.3231\n",
      "Iteration 5570 : Loss 3539.2059\n",
      "Iteration 5580 : Loss 3539.0896\n",
      "Iteration 5590 : Loss 3538.9741\n",
      "Iteration 5600 : Loss 3538.8595\n",
      "Iteration 5610 : Loss 3538.7458\n",
      "Iteration 5620 : Loss 3538.6329\n",
      "Iteration 5630 : Loss 3538.5209\n",
      "Iteration 5640 : Loss 3538.4097\n",
      "Iteration 5650 : Loss 3538.2993\n",
      "Iteration 5660 : Loss 3538.1897\n",
      "Iteration 5670 : Loss 3538.0810\n",
      "Iteration 5680 : Loss 3537.9730\n",
      "Iteration 5690 : Loss 3537.8659\n",
      "Iteration 5700 : Loss 3537.7596\n",
      "Iteration 5710 : Loss 3537.6540\n",
      "Iteration 5720 : Loss 3537.5492\n",
      "Iteration 5730 : Loss 3537.4452\n",
      "Iteration 5740 : Loss 3537.3420\n",
      "Iteration 5750 : Loss 3537.2396\n",
      "Iteration 5760 : Loss 3537.1378\n",
      "Iteration 5770 : Loss 3537.0369\n",
      "Iteration 5780 : Loss 3536.9367\n",
      "Iteration 5790 : Loss 3536.8372\n",
      "Iteration 5800 : Loss 3536.7385\n",
      "Iteration 5810 : Loss 3536.6405\n",
      "Iteration 5820 : Loss 3536.5432\n",
      "Iteration 5830 : Loss 3536.4466\n",
      "Iteration 5840 : Loss 3536.3508\n",
      "Iteration 5850 : Loss 3536.2556\n",
      "Iteration 5860 : Loss 3536.1612\n",
      "Iteration 5870 : Loss 3536.0674\n",
      "Iteration 5880 : Loss 3535.9743\n",
      "Iteration 5890 : Loss 3535.8819\n",
      "Iteration 5900 : Loss 3535.7902\n",
      "Iteration 5910 : Loss 3535.6992\n",
      "Iteration 5920 : Loss 3535.6088\n",
      "Iteration 5930 : Loss 3535.5191\n",
      "Iteration 5940 : Loss 3535.4300\n",
      "Iteration 5950 : Loss 3535.3416\n",
      "Iteration 5960 : Loss 3535.2538\n",
      "Iteration 5970 : Loss 3535.1667\n",
      "Iteration 5980 : Loss 3535.0802\n",
      "Iteration 5990 : Loss 3534.9943\n",
      "Iteration 6000 : Loss 3534.9091\n",
      "Iteration 6010 : Loss 3534.8245\n",
      "Iteration 6020 : Loss 3534.7405\n",
      "Iteration 6030 : Loss 3534.6571\n",
      "Iteration 6040 : Loss 3534.5743\n",
      "Iteration 6050 : Loss 3534.4921\n",
      "Iteration 6060 : Loss 3534.4105\n",
      "Iteration 6070 : Loss 3534.3295\n",
      "Iteration 6080 : Loss 3534.2491\n",
      "Iteration 6090 : Loss 3534.1693\n",
      "Iteration 6100 : Loss 3534.0900\n",
      "Iteration 6110 : Loss 3534.0113\n",
      "Iteration 6120 : Loss 3533.9332\n",
      "Iteration 6130 : Loss 3533.8557\n",
      "Iteration 6140 : Loss 3533.7787\n",
      "Iteration 6150 : Loss 3533.7022\n",
      "Iteration 6160 : Loss 3533.6264\n",
      "Iteration 6170 : Loss 3533.5510\n",
      "Iteration 6180 : Loss 3533.4762\n",
      "Iteration 6190 : Loss 3533.4020\n",
      "Iteration 6200 : Loss 3533.3282\n",
      "Iteration 6210 : Loss 3533.2550\n",
      "Iteration 6220 : Loss 3533.1824\n",
      "Iteration 6230 : Loss 3533.1102\n",
      "Iteration 6240 : Loss 3533.0386\n",
      "Iteration 6250 : Loss 3532.9675\n",
      "Iteration 6260 : Loss 3532.8969\n",
      "Iteration 6270 : Loss 3532.8268\n",
      "Iteration 6280 : Loss 3532.7572\n",
      "Iteration 6290 : Loss 3532.6881\n",
      "Iteration 6300 : Loss 3532.6195\n",
      "Iteration 6310 : Loss 3532.5513\n",
      "Iteration 6320 : Loss 3532.4837\n",
      "Iteration 6330 : Loss 3532.4166\n",
      "Iteration 6340 : Loss 3532.3499\n",
      "Iteration 6350 : Loss 3532.2837\n",
      "Iteration 6360 : Loss 3532.2180\n",
      "Iteration 6370 : Loss 3532.1527\n",
      "Iteration 6380 : Loss 3532.0879\n",
      "Iteration 6390 : Loss 3532.0236\n",
      "Iteration 6400 : Loss 3531.9597\n",
      "Iteration 6410 : Loss 3531.8963\n",
      "Iteration 6420 : Loss 3531.8333\n",
      "Iteration 6430 : Loss 3531.7708\n",
      "Iteration 6440 : Loss 3531.7087\n",
      "Iteration 6450 : Loss 3531.6470\n",
      "Iteration 6460 : Loss 3531.5858\n",
      "Iteration 6470 : Loss 3531.5251\n",
      "Iteration 6480 : Loss 3531.4647\n",
      "Iteration 6490 : Loss 3531.4048\n",
      "Iteration 6500 : Loss 3531.3453\n",
      "Iteration 6510 : Loss 3531.2862\n",
      "Iteration 6520 : Loss 3531.2276\n",
      "Iteration 6530 : Loss 3531.1693\n",
      "Iteration 6540 : Loss 3531.1115\n",
      "Iteration 6550 : Loss 3531.0541\n",
      "Iteration 6560 : Loss 3530.9970\n",
      "Iteration 6570 : Loss 3530.9404\n",
      "Iteration 6580 : Loss 3530.8842\n",
      "Iteration 6590 : Loss 3530.8284\n",
      "Iteration 6600 : Loss 3530.7729\n",
      "Iteration 6610 : Loss 3530.7179\n",
      "Iteration 6620 : Loss 3530.6632\n",
      "Iteration 6630 : Loss 3530.6089\n",
      "Iteration 6640 : Loss 3530.5550\n",
      "Iteration 6650 : Loss 3530.5015\n",
      "Iteration 6660 : Loss 3530.4484\n",
      "Iteration 6670 : Loss 3530.3956\n",
      "Iteration 6680 : Loss 3530.3432\n",
      "Iteration 6690 : Loss 3530.2912\n",
      "Iteration 6700 : Loss 3530.2395\n",
      "Iteration 6710 : Loss 3530.1882\n",
      "Iteration 6720 : Loss 3530.1372\n",
      "Iteration 6730 : Loss 3530.0866\n",
      "Iteration 6740 : Loss 3530.0364\n",
      "Iteration 6750 : Loss 3529.9865\n",
      "Iteration 6760 : Loss 3529.9369\n",
      "Iteration 6770 : Loss 3529.8877\n",
      "Iteration 6780 : Loss 3529.8389\n",
      "Iteration 6790 : Loss 3529.7903\n",
      "Iteration 6800 : Loss 3529.7421\n",
      "Iteration 6810 : Loss 3529.6943\n",
      "Iteration 6820 : Loss 3529.6468\n",
      "Iteration 6830 : Loss 3529.5996\n",
      "Iteration 6840 : Loss 3529.5527\n",
      "Iteration 6850 : Loss 3529.5062\n",
      "Iteration 6860 : Loss 3529.4600\n",
      "Iteration 6870 : Loss 3529.4141\n",
      "Iteration 6880 : Loss 3529.3685\n",
      "Iteration 6890 : Loss 3529.3232\n",
      "Iteration 6900 : Loss 3529.2783\n",
      "Iteration 6910 : Loss 3529.2336\n",
      "Iteration 6920 : Loss 3529.1893\n",
      "Iteration 6930 : Loss 3529.1453\n",
      "Iteration 6940 : Loss 3529.1016\n",
      "Iteration 6950 : Loss 3529.0581\n",
      "Iteration 6960 : Loss 3529.0150\n",
      "Iteration 6970 : Loss 3528.9722\n",
      "Iteration 6980 : Loss 3528.9297\n",
      "Iteration 6990 : Loss 3528.8874\n",
      "Iteration 7000 : Loss 3528.8455\n",
      "Iteration 7010 : Loss 3528.8038\n",
      "Iteration 7020 : Loss 3528.7624\n",
      "Iteration 7030 : Loss 3528.7214\n",
      "Iteration 7040 : Loss 3528.6805\n",
      "Iteration 7050 : Loss 3528.6400\n",
      "Iteration 7060 : Loss 3528.5998\n",
      "Iteration 7070 : Loss 3528.5598\n",
      "Iteration 7080 : Loss 3528.5201\n",
      "Iteration 7090 : Loss 3528.4807\n",
      "Iteration 7100 : Loss 3528.4415\n",
      "Iteration 7110 : Loss 3528.4026\n",
      "Iteration 7120 : Loss 3528.3640\n",
      "Iteration 7130 : Loss 3528.3256\n",
      "Iteration 7140 : Loss 3528.2875\n",
      "Iteration 7150 : Loss 3528.2497\n",
      "Iteration 7160 : Loss 3528.2121\n",
      "Iteration 7170 : Loss 3528.1748\n",
      "Iteration 7180 : Loss 3528.1377\n",
      "Iteration 7190 : Loss 3528.1009\n",
      "Iteration 7200 : Loss 3528.0643\n",
      "Iteration 7210 : Loss 3528.0280\n",
      "Iteration 7220 : Loss 3527.9919\n",
      "Iteration 7230 : Loss 3527.9561\n",
      "Iteration 7240 : Loss 3527.9205\n",
      "Iteration 7250 : Loss 3527.8852\n",
      "Iteration 7260 : Loss 3527.8501\n",
      "Iteration 7270 : Loss 3527.8152\n",
      "Iteration 7280 : Loss 3527.7806\n",
      "Iteration 7290 : Loss 3527.7462\n",
      "Iteration 7300 : Loss 3527.7120\n",
      "Iteration 7310 : Loss 3527.6781\n",
      "Iteration 7320 : Loss 3527.6444\n",
      "Iteration 7330 : Loss 3527.6110\n",
      "Iteration 7340 : Loss 3527.5777\n",
      "Iteration 7350 : Loss 3527.5447\n",
      "Iteration 7360 : Loss 3527.5119\n",
      "Iteration 7370 : Loss 3527.4793\n",
      "Iteration 7380 : Loss 3527.4470\n",
      "Iteration 7390 : Loss 3527.4148\n",
      "Iteration 7400 : Loss 3527.3829\n",
      "Iteration 7410 : Loss 3527.3512\n",
      "Iteration 7420 : Loss 3527.3197\n",
      "Iteration 7430 : Loss 3527.2884\n",
      "Iteration 7440 : Loss 3527.2574\n",
      "Iteration 7450 : Loss 3527.2265\n",
      "Iteration 7460 : Loss 3527.1958\n",
      "Iteration 7470 : Loss 3527.1654\n",
      "Iteration 7480 : Loss 3527.1352\n",
      "Iteration 7490 : Loss 3527.1051\n",
      "Iteration 7500 : Loss 3527.0753\n",
      "Iteration 7510 : Loss 3527.0456\n",
      "Iteration 7520 : Loss 3527.0162\n",
      "Iteration 7530 : Loss 3526.9870\n",
      "Iteration 7540 : Loss 3526.9579\n",
      "Iteration 7550 : Loss 3526.9291\n",
      "Iteration 7560 : Loss 3526.9004\n",
      "Iteration 7570 : Loss 3526.8719\n",
      "Iteration 7580 : Loss 3526.8437\n",
      "Iteration 7590 : Loss 3526.8156\n",
      "Iteration 7600 : Loss 3526.7877\n",
      "Iteration 7610 : Loss 3526.7600\n",
      "Iteration 7620 : Loss 3526.7324\n",
      "Iteration 7630 : Loss 3526.7051\n",
      "Iteration 7640 : Loss 3526.6779\n",
      "Iteration 7650 : Loss 3526.6509\n",
      "Iteration 7660 : Loss 3526.6241\n",
      "Iteration 7670 : Loss 3526.5975\n",
      "Iteration 7680 : Loss 3526.5711\n",
      "Iteration 7690 : Loss 3526.5448\n",
      "Iteration 7700 : Loss 3526.5187\n",
      "Iteration 7710 : Loss 3526.4928\n",
      "Iteration 7720 : Loss 3526.4670\n",
      "Iteration 7730 : Loss 3526.4415\n",
      "Iteration 7740 : Loss 3526.4161\n",
      "Iteration 7750 : Loss 3526.3908\n",
      "Iteration 7760 : Loss 3526.3657\n",
      "Iteration 7770 : Loss 3526.3408\n",
      "Iteration 7780 : Loss 3526.3161\n",
      "Iteration 7790 : Loss 3526.2915\n",
      "Iteration 7800 : Loss 3526.2671\n",
      "Iteration 7810 : Loss 3526.2428\n",
      "Iteration 7820 : Loss 3526.2188\n",
      "Iteration 7830 : Loss 3526.1948\n",
      "Iteration 7840 : Loss 3526.1710\n",
      "Iteration 7850 : Loss 3526.1474\n",
      "Iteration 7860 : Loss 3526.1240\n",
      "Iteration 7870 : Loss 3526.1007\n",
      "Iteration 7880 : Loss 3526.0775\n",
      "Iteration 7890 : Loss 3526.0545\n",
      "Iteration 7900 : Loss 3526.0316\n",
      "Iteration 7910 : Loss 3526.0089\n",
      "Iteration 7920 : Loss 3525.9864\n",
      "Iteration 7930 : Loss 3525.9640\n",
      "Iteration 7940 : Loss 3525.9417\n",
      "Iteration 7950 : Loss 3525.9196\n",
      "Iteration 7960 : Loss 3525.8977\n",
      "Iteration 7970 : Loss 3525.8759\n",
      "Iteration 7980 : Loss 3525.8542\n",
      "Iteration 7990 : Loss 3525.8326\n",
      "Iteration 8000 : Loss 3525.8113\n",
      "Iteration 8010 : Loss 3525.7900\n",
      "Iteration 8020 : Loss 3525.7689\n",
      "Iteration 8030 : Loss 3525.7479\n",
      "Iteration 8040 : Loss 3525.7271\n",
      "Iteration 8050 : Loss 3525.7064\n",
      "Iteration 8060 : Loss 3525.6858\n",
      "Iteration 8070 : Loss 3525.6654\n",
      "Iteration 8080 : Loss 3525.6451\n",
      "Iteration 8090 : Loss 3525.6249\n",
      "Iteration 8100 : Loss 3525.6049\n",
      "Iteration 8110 : Loss 3525.5850\n",
      "Iteration 8120 : Loss 3525.5652\n",
      "Iteration 8130 : Loss 3525.5456\n",
      "Iteration 8140 : Loss 3525.5261\n",
      "Iteration 8150 : Loss 3525.5067\n",
      "Iteration 8160 : Loss 3525.4874\n",
      "Iteration 8170 : Loss 3525.4683\n",
      "Iteration 8180 : Loss 3525.4493\n",
      "Iteration 8190 : Loss 3525.4304\n",
      "Iteration 8200 : Loss 3525.4116\n",
      "Iteration 8210 : Loss 3525.3930\n",
      "Iteration 8220 : Loss 3525.3745\n",
      "Iteration 8230 : Loss 3525.3561\n",
      "Iteration 8240 : Loss 3525.3378\n",
      "Iteration 8250 : Loss 3525.3196\n",
      "Iteration 8260 : Loss 3525.3016\n",
      "Iteration 8270 : Loss 3525.2837\n",
      "Iteration 8280 : Loss 3525.2659\n",
      "Iteration 8290 : Loss 3525.2482\n",
      "Iteration 8300 : Loss 3525.2306\n",
      "Iteration 8310 : Loss 3525.2131\n",
      "Iteration 8320 : Loss 3525.1958\n",
      "Iteration 8330 : Loss 3525.1785\n",
      "Iteration 8340 : Loss 3525.1614\n",
      "Iteration 8350 : Loss 3525.1444\n",
      "Iteration 8360 : Loss 3525.1275\n",
      "Iteration 8370 : Loss 3525.1107\n",
      "Iteration 8380 : Loss 3525.0940\n",
      "Iteration 8390 : Loss 3525.0774\n",
      "Iteration 8400 : Loss 3525.0609\n",
      "Iteration 8410 : Loss 3525.0446\n",
      "Iteration 8420 : Loss 3525.0283\n",
      "Iteration 8430 : Loss 3525.0121\n",
      "Iteration 8440 : Loss 3524.9961\n",
      "Iteration 8450 : Loss 3524.9801\n",
      "Iteration 8460 : Loss 3524.9643\n",
      "Iteration 8470 : Loss 3524.9485\n",
      "Iteration 8480 : Loss 3524.9329\n",
      "Iteration 8490 : Loss 3524.9173\n",
      "Iteration 8500 : Loss 3524.9019\n",
      "Iteration 8510 : Loss 3524.8866\n",
      "Iteration 8520 : Loss 3524.8713\n",
      "Iteration 8530 : Loss 3524.8562\n",
      "Iteration 8540 : Loss 3524.8411\n",
      "Iteration 8550 : Loss 3524.8261\n",
      "Iteration 8560 : Loss 3524.8113\n",
      "Iteration 8570 : Loss 3524.7965\n",
      "Iteration 8580 : Loss 3524.7819\n",
      "Iteration 8590 : Loss 3524.7673\n",
      "Iteration 8600 : Loss 3524.7528\n",
      "Iteration 8610 : Loss 3524.7384\n",
      "Iteration 8620 : Loss 3524.7241\n",
      "Iteration 8630 : Loss 3524.7099\n",
      "Iteration 8640 : Loss 3524.6958\n",
      "Iteration 8650 : Loss 3524.6818\n",
      "Iteration 8660 : Loss 3524.6678\n",
      "Iteration 8670 : Loss 3524.6540\n",
      "Iteration 8680 : Loss 3524.6402\n",
      "Iteration 8690 : Loss 3524.6266\n",
      "Iteration 8700 : Loss 3524.6130\n",
      "Iteration 8710 : Loss 3524.5995\n",
      "Iteration 8720 : Loss 3524.5861\n",
      "Iteration 8730 : Loss 3524.5727\n",
      "Iteration 8740 : Loss 3524.5595\n",
      "Iteration 8750 : Loss 3524.5463\n",
      "Iteration 8760 : Loss 3524.5333\n",
      "Iteration 8770 : Loss 3524.5203\n",
      "Iteration 8780 : Loss 3524.5074\n",
      "Iteration 8790 : Loss 3524.4946\n",
      "Iteration 8800 : Loss 3524.4818\n",
      "Iteration 8810 : Loss 3524.4691\n",
      "Iteration 8820 : Loss 3524.4566\n",
      "Iteration 8830 : Loss 3524.4441\n",
      "Iteration 8840 : Loss 3524.4316\n",
      "Iteration 8850 : Loss 3524.4193\n",
      "Iteration 8860 : Loss 3524.4070\n",
      "Iteration 8870 : Loss 3524.3948\n",
      "Iteration 8880 : Loss 3524.3827\n",
      "Iteration 8890 : Loss 3524.3707\n",
      "Iteration 8900 : Loss 3524.3587\n",
      "Iteration 8910 : Loss 3524.3469\n",
      "Iteration 8920 : Loss 3524.3351\n",
      "Iteration 8930 : Loss 3524.3233\n",
      "Iteration 8940 : Loss 3524.3117\n",
      "Iteration 8950 : Loss 3524.3001\n",
      "Iteration 8960 : Loss 3524.2886\n",
      "Iteration 8970 : Loss 3524.2771\n",
      "Iteration 8980 : Loss 3524.2658\n",
      "Iteration 8990 : Loss 3524.2545\n",
      "Iteration 9000 : Loss 3524.2432\n",
      "Iteration 9010 : Loss 3524.2321\n",
      "Iteration 9020 : Loss 3524.2210\n",
      "Iteration 9030 : Loss 3524.2100\n",
      "Iteration 9040 : Loss 3524.1990\n",
      "Iteration 9050 : Loss 3524.1882\n",
      "Iteration 9060 : Loss 3524.1774\n",
      "Iteration 9070 : Loss 3524.1666\n",
      "Iteration 9080 : Loss 3524.1560\n",
      "Iteration 9090 : Loss 3524.1454\n",
      "Iteration 9100 : Loss 3524.1348\n",
      "Iteration 9110 : Loss 3524.1243\n",
      "Iteration 9120 : Loss 3524.1139\n",
      "Iteration 9130 : Loss 3524.1036\n",
      "Iteration 9140 : Loss 3524.0933\n",
      "Iteration 9150 : Loss 3524.0831\n",
      "Iteration 9160 : Loss 3524.0730\n",
      "Iteration 9170 : Loss 3524.0629\n",
      "Iteration 9180 : Loss 3524.0529\n",
      "Iteration 9190 : Loss 3524.0429\n",
      "Iteration 9200 : Loss 3524.0330\n",
      "Iteration 9210 : Loss 3524.0232\n",
      "Iteration 9220 : Loss 3524.0134\n",
      "Iteration 9230 : Loss 3524.0037\n",
      "Iteration 9240 : Loss 3523.9940\n",
      "Iteration 9250 : Loss 3523.9845\n",
      "Iteration 9260 : Loss 3523.9749\n",
      "Iteration 9270 : Loss 3523.9655\n",
      "Iteration 9280 : Loss 3523.9560\n",
      "Iteration 9290 : Loss 3523.9467\n",
      "Iteration 9300 : Loss 3523.9374\n",
      "Iteration 9310 : Loss 3523.9282\n",
      "Iteration 9320 : Loss 3523.9190\n",
      "Iteration 9330 : Loss 3523.9099\n",
      "Iteration 9340 : Loss 3523.9008\n",
      "Iteration 9350 : Loss 3523.8918\n",
      "Iteration 9360 : Loss 3523.8828\n",
      "Iteration 9370 : Loss 3523.8739\n",
      "Iteration 9380 : Loss 3523.8651\n",
      "Iteration 9390 : Loss 3523.8563\n",
      "Iteration 9400 : Loss 3523.8476\n",
      "Iteration 9410 : Loss 3523.8389\n",
      "Iteration 9420 : Loss 3523.8303\n",
      "Iteration 9430 : Loss 3523.8217\n",
      "Iteration 9440 : Loss 3523.8132\n",
      "Iteration 9450 : Loss 3523.8047\n",
      "Iteration 9460 : Loss 3523.7963\n",
      "Iteration 9470 : Loss 3523.7879\n",
      "Iteration 9480 : Loss 3523.7796\n",
      "Iteration 9490 : Loss 3523.7714\n",
      "Iteration 9500 : Loss 3523.7632\n",
      "Iteration 9510 : Loss 3523.7550\n",
      "Iteration 9520 : Loss 3523.7469\n",
      "Iteration 9530 : Loss 3523.7389\n",
      "Iteration 9540 : Loss 3523.7309\n",
      "Iteration 9550 : Loss 3523.7229\n",
      "Iteration 9560 : Loss 3523.7150\n",
      "Iteration 9570 : Loss 3523.7071\n",
      "Iteration 9580 : Loss 3523.6993\n",
      "Iteration 9590 : Loss 3523.6916\n",
      "Iteration 9600 : Loss 3523.6839\n",
      "Iteration 9610 : Loss 3523.6762\n",
      "Iteration 9620 : Loss 3523.6686\n",
      "Iteration 9630 : Loss 3523.6610\n",
      "Iteration 9640 : Loss 3523.6535\n",
      "Iteration 9650 : Loss 3523.6460\n",
      "Iteration 9660 : Loss 3523.6386\n",
      "Iteration 9670 : Loss 3523.6312\n",
      "Iteration 9680 : Loss 3523.6238\n",
      "Iteration 9690 : Loss 3523.6166\n",
      "Iteration 9700 : Loss 3523.6093\n",
      "Iteration 9710 : Loss 3523.6021\n",
      "Iteration 9720 : Loss 3523.5949\n",
      "Iteration 9730 : Loss 3523.5878\n",
      "Iteration 9740 : Loss 3523.5807\n",
      "Iteration 9750 : Loss 3523.5737\n",
      "Iteration 9760 : Loss 3523.5667\n",
      "Iteration 9770 : Loss 3523.5598\n",
      "Iteration 9780 : Loss 3523.5529\n",
      "Iteration 9790 : Loss 3523.5460\n",
      "Iteration 9800 : Loss 3523.5392\n",
      "Iteration 9810 : Loss 3523.5324\n",
      "Iteration 9820 : Loss 3523.5257\n",
      "Iteration 9830 : Loss 3523.5190\n",
      "Iteration 9840 : Loss 3523.5123\n",
      "Iteration 9850 : Loss 3523.5057\n",
      "Iteration 9860 : Loss 3523.4992\n",
      "Iteration 9870 : Loss 3523.4926\n",
      "Iteration 9880 : Loss 3523.4861\n",
      "Iteration 9890 : Loss 3523.4797\n",
      "Iteration 9900 : Loss 3523.4733\n",
      "Iteration 9910 : Loss 3523.4669\n",
      "Iteration 9920 : Loss 3523.4606\n",
      "Iteration 9930 : Loss 3523.4543\n",
      "Iteration 9940 : Loss 3523.4480\n",
      "Iteration 9950 : Loss 3523.4418\n",
      "Iteration 9960 : Loss 3523.4356\n",
      "Iteration 9970 : Loss 3523.4295\n",
      "Iteration 9980 : Loss 3523.4234\n",
      "Iteration 9990 : Loss 3523.4173\n",
      "Iteration 10000 : Loss 3523.4113\n"
     ]
    }
   ],
   "source": [
    "re_losses = []\n",
    "for i in range(1, 10001):\n",
    "    dW, db = gradient(re_X_train, re_W, re_b, re_y_train)\n",
    "    re_W -= LEARNING_RATE * dW\n",
    "    re_b -= LEARNING_RATE * db\n",
    "    L = loss(re_X_train, re_W, re_b, re_y_train)\n",
    "    re_losses.append(L)\n",
    "    if i % 10 == 0:\n",
    "        print(\"Iteration %d : Loss %0.4f\" %(i,L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cddfd7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(re_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78526c65",
   "metadata": {},
   "source": [
    "## test 데이터에 대한 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af39fc85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3705.822084073241"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_prediction = model(re_X_test,re_W, re_b)\n",
    "mse1 = loss(re_X_test,re_W, re_b, re_y_test)\n",
    "mse1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b40fbd",
   "metadata": {},
   "source": [
    "## 정답 데이터와 예측 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1190fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(re_X_test[:,0], re_y_test, c = 'r')\n",
    "plt.scatter(re_X_test[:,0], re_prediction, c = 'y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
